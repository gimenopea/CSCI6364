{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment Setup**\n",
    "**There are 5 algorithms applied in our dataset:**\n",
    "1. Tuned logistic regression\n",
    "2. Principal Component Analysis and Logistic Regression\n",
    "3. Random Forest Classifier \n",
    "4. Ensemble Gradient Boosting Classifier with tuned parameters\n",
    "5. Stacking Algorithm with a logistic regression meta model (final classifier)\n",
    "\n",
    "**These 5 algorithms are applied in 4 areas so that we can predict election winner outcomes in:**\n",
    "\n",
    " 1.  Senate Seats\n",
    " 2.  House Seats\n",
    " 3.  Presidential Sets\n",
    " 4.  All Seats (Senate, House, Presidential)\n",
    " \n",
    " **Algorithms 1 - 4 will produce 16 .pkl model files as shown below.**\n",
    " \n",
    " **Algorithm 5 will produce 1 Stacking Algorithm model using the 16 .pkl models and produce 4 .pkl model files for a total of 20 .pkl model files.**\n",
    "\n",
    " **All algorithms will use cross validation (k=5) to determine the best parameters for each model.**\n",
    "\n",
    " **All algorithms will use a holdout test set to determine the accuracy and f1 score. We will base our final model selection highest accuracy and f1 score.**\n",
    " \n",
    "\n",
    "|Model #|Model Filename|Model Description\n",
    "|--|--|--\n",
    "|1|senate-tuned-lr|logistic regression on senate candidates with tuned hyperparameters\n",
    "|2|house-tuned-lr|logistic regression on house candidates with tuned hyperparameters\n",
    "|3|pres-tuned-lr|logistic regression on presidential candidates with tuned hyperparameters\n",
    "|4|all-tuned-lr|logistic regression on all candidates with tuned hyperparameters\n",
    "|5|senate-pca-lr|pca + logistic regression on senate candidates\n",
    "|6|house-pca-lr|pca + logistic regression on house candidates\n",
    "|7|pres-pca-lr|pca + logistic regression on presidential candidates\n",
    "|8|all-pca-lr|pca + logistic regression on all candidates\n",
    "|9|senate-rf|random forest classificer on senate candidates\n",
    "|10|house-rf|random forest classificer on senate candidates\n",
    "|11|pres-rf|random forest classificer on senate candidates\n",
    "|12|all-rf|random forest classificer on senate candidates\n",
    "|13|senate-gb|gradient boosting algo on senate candidates\n",
    "|14|house-gb|gradient boosting algo on senate candidates\n",
    "|15|pres-gb|gradient boosting algo on senate candidates\n",
    "|16|all-gb|gradient boosting algo on senate candidates\n",
    "\n",
    "\n",
    "**Comparison to baseline**\n",
    "\n",
    "At the end of this notebook, we will compare our model to a classifier that only predicts on the majority class. This will be our baseline metric. We will prove that our model is better than the baseline model by showing that our model has a higher accuracy than the baseline model\n",
    "\n",
    "\n",
    "**Libraries used**\n",
    "\n",
    "- numpy for numerical analysis\n",
    "- pandas for data manipulation\n",
    "- matplotlib for data visualization\n",
    "- seaborn for data visualization\n",
    "- sklearn for machine learning algorithms\n",
    "- pickle for saving models\n",
    "\n",
    "**code snippet attribution**\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html : for grid search implementation\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html :  for lr implementation\n",
    "- https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74:  for rf grid search implementation and the basis for gradient boosting implementation\n",
    "- https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/ : for stacking implementation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of flattened feature engineered data can be referenced here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('data/all_features_candidate_summary_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run function for data pre-processing\n",
    "def pre_process(df):   \n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['run_for_state','run_for_district','cand_party'])\n",
    "    #split x and y\n",
    "    y = df['label']\n",
    "    x = df.drop(['label'], axis=1)\n",
    "\n",
    "    #remove collinear and redundant features as they can skew our Beta coefficients variables\n",
    "    #if x has columned called 'Unnamed: 0'\n",
    "    if 'Unnamed: 0' in x.columns:\n",
    "        x = x.drop(['Unnamed: 0','CycleCands_x','curr_cand','RepeatDonorCount','CycleCands_y','challenger','FemaleDonorCount','TotalGiftAvg.1','open_office'], axis=1)\n",
    "    else:\n",
    "        x = x.drop(['curr_cand','RepeatDonorCount','challenger','FemaleDonorCount','TotalGiftAvg.1'], axis=1)\n",
    "\n",
    "    #drop non numeric columns in x\n",
    "    x = x.select_dtypes(include=['float64','int64','uint8','int32'])\n",
    "      \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senate = df[df['senate_seat'] == 1].copy()\n",
    "df_presidential = df[df['presidential_seat'] == 1].copy()\n",
    "df_house = df[df['house_seat'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senate seat row count:  1141\n",
      "Presidential seat row count:  433\n",
      "House seat row count:  8050\n",
      "All row count:  9592\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print row count for each dataframe\n",
    "print('Senate seat row count: ', df_senate.shape[0])\n",
    "print('Presidential seat row count: ', df_presidential.shape[0])\n",
    "print('House seat row count: ', df_house.shape[0])\n",
    "print('All row count: ', df.shape[0])\n",
    "%matplotlib inline \n",
    "\n",
    "#plot the distribution of the labels\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "sns.countplot(x='label', data=df_senate, ax=ax[0])\n",
    "sns.countplot(x='label', data=df_presidential, ax=ax[1])\n",
    "sns.countplot(x='label', data=df_house, ax=ax[2])\n",
    "#show percentage of labels in the plot\n",
    "for i in range(3):\n",
    "    total = len(df_senate) if i == 0 else len(df_presidential) if i == 1 else len(df_house)\n",
    "    for p in ax[i].patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax[i].annotate(percentage, (x, y))\n",
    "ax[0].set_title('Senate')\n",
    "ax[1].set_title('Presidential')\n",
    "ax[2].set_title('House')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Tuned Logistic Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a. Helper functions to run this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for this task\n",
    "def plot_correlation(x,y, set_name=None):\n",
    "    ''' Function to plot correlation between features and labels '''\n",
    "    correlation = x.corrwith(y)\n",
    "    correlation = correlation.sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.barh(correlation.index, correlation.values)   \n",
    "    plt.title(f'Correlation of Features with Target on {set_name} seats')\n",
    "    plt.xlabel('Correlation')\n",
    "    plt.savefig(f'plots/1-{set_name}-correlation-lr.png')\n",
    "    #plt.show()\n",
    "\n",
    "def grid_search_tuned_lr(x_train, y_train, cv=5):\n",
    "    ''' Function to perform grid search on logistic regression '''\n",
    "    logreg = LogisticRegression(max_iter=1000, tol=.001)\n",
    "    std_scaler = StandardScaler()\n",
    "    pipeline = make_pipeline(std_scaler, logreg)\n",
    "\n",
    "    params = [\n",
    "  {'logisticregression__penalty': ['l1'], 'logisticregression__solver': ['liblinear', 'sag','saga'], 'logisticregression__C': [0.01, 0.1, 1, 10], 'logisticregression__class_weight': ['balanced', None]},\n",
    "  {'logisticregression__penalty': ['l2'], 'logisticregression__solver': ['lbfgs','newton-cg'],'logisticregression__C': [0.01, 0.1, 1, 10], 'logisticregression__class_weight': ['balanced', None]},\n",
    " ]\n",
    "    \n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(x_train, y_train)\n",
    "    print('best score: ', grid.best_score_)\n",
    "    print('best params: ', grid.best_params_)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def fit_using_best_params_lr(x_train, y_train, grid_search = None):\n",
    "    ''' function to fit the model using the best params from grid search '''\n",
    "    if grid_search is not None:\n",
    "        best_c = grid_search.best_params_['logisticregression__C']\n",
    "        best_class_weight = grid_search.best_params_['logisticregression__class_weight']\n",
    "        best_penalty = grid_search.best_params_['logisticregression__penalty']\n",
    "        best_solver = grid_search.best_params_['logisticregression__solver']\n",
    "        \n",
    "    #save best params to a dictionary\n",
    "    best_params = {'C':best_c, 'class_weight':best_class_weight, 'penalty':best_penalty}\n",
    "    pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, C=best_c, class_weight=best_class_weight, solver=best_solver,penalty=best_penalty, tol=.001))\n",
    "    pipeline.fit(x_train, y_train)  \n",
    "    \n",
    "    return pipeline, best_params\n",
    "    \n",
    "\n",
    "def get_feature_importance(pipeline, x_val, set_name = None):\n",
    "    ''' Function to plot feature importance after logistic regression '''\n",
    "   \n",
    "    feature_importance = pipeline.steps[1][1].coef_[0]\n",
    "\n",
    "    feature_names = x_val.columns\n",
    "    feature_importance_df = pd.DataFrame({'feature':feature_names, 'importance':feature_importance})\n",
    "    #sort by importance\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.barh(feature_importance_df['feature'], feature_importance_df['importance'])\n",
    "    plt.title(f'Feature Importance on {set_name} seats')\n",
    "    plt.xlabel('Importance')     \n",
    "    plt.savefig(f'plots/3-{set_name}-feature-importance-lr.png')\n",
    "    #plt.show() \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "#evaluate model function\n",
    "def evaluate_model(model, x_train, y_train, x_val, y_val, set_name = None,best_params = None):\n",
    "    ''' Function to evaluate model on train and validation set '''   \n",
    "    #save accuracy, precision, recall, f1 score\n",
    "    train_accuracy = model.score(x_train, y_train)\n",
    "    val_accuracy = model.score(x_val, y_val)\n",
    "\n",
    "    #predict on train and validation set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_val_pred = model.predict(x_val)\n",
    "\n",
    "    #recall\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "\n",
    "    #precision\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    #f1 score\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)  \n",
    "\n",
    "    #save all metrics and best params to a dataframe\n",
    "    metrics_df = pd.DataFrame({'experiment_name': f'Logistic Regression {set_name} seats', \n",
    "    'train_accuracy':[train_accuracy], \n",
    "    'test_accuracy':[val_accuracy], \n",
    "    'train_precision':[train_precision], \n",
    "    'test_precision':[val_precision],\n",
    "    'train_recall':[train_recall], \n",
    "    'test_recall':[val_recall],      \n",
    "    'train_f1':[train_f1], \n",
    "    'test_f1':[val_f1],\n",
    "    'hyperparameters':[best_params]})    \n",
    "    return metrics_df\n",
    "\n",
    "def run_sequence_lr(x_train, y_train, x_val, y_val, set_name = None):\n",
    "    #get correlation\n",
    "    #correlation = plot_correlation(x_train, y_train, set_name)\n",
    "    #label distribution\n",
    "    #label_distribution(y_train, set_name)\n",
    "    #grid search\n",
    "    grid_search = grid_search_tuned_lr(x_train, y_train)\n",
    "    #fit using best params\n",
    "    model, best_params = fit_using_best_params_lr(x_train, y_train, grid_search)    \n",
    "    #get feature importance\n",
    "    feature_importance = get_feature_importance(model, x_train, set_name)\n",
    "    #evaluate model\n",
    "    metrics_df = evaluate_model(model, x_train, y_train, x_val, y_val, set_name=set_name, best_params=best_params)\n",
    "    #save model to pickle\n",
    "    model_name = f'models/{set_name}-tuned-lr.pkl'\n",
    "    pickle.dump(model, open(model_name, 'wb'))\n",
    "    #add column to metrics_df called model_name on index 1\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #display metrics_df dataframe\n",
    "    display(metrics_df)     \n",
    "    metrics_df.to_csv('models/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['experiment_name', \n",
    "'model_name', 'train_accuracy', \n",
    "'test_accuracy', 'train_precision', 'test_precision', 'train_recall', 'test_recall', 'train_f1', 'test_f1', 'hyperparameters'])\n",
    "filename = f'models/metrics.csv'\n",
    "metrics_df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b. Run Logistic Regression sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.948465741908365\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    experiment_name                  model_name  \\\n",
       "0  Logistic Regression senate seats  models/senate-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg \n",
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c. Run Logistic Regression sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9475155279503106\n",
      "best params:  {'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   experiment_name                 model_name  train_accuracy  \\\n",
       "0  Logistic Regression house seats  models/house-tuned-lr.pkl        0.947981   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.952795         0.912703        0.940054      0.888628     0.864662   \n",
       "\n",
       "   train_f1   test_f1                                     hyperparameters  \n",
       "0  0.900505  0.900783  {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg \n",
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d. Run Logistic Regression sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9364389233954451\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment_name                        model_name  \\\n",
       "0  Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.945087       0.896552         0.941176         0.73913   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.810127         0.85  0.870748  0.790698   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg\n",
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e. Run Logistic Regression sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9401807456607877\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_name               model_name  train_accuracy  \\\n",
       "0  Logistic Regression all seats  models/all-tuned-lr.pkl        0.942526   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.944763         0.880729        0.882845      0.888597     0.894068   \n",
       "\n",
       "   train_f1   test_f1                                    hyperparameters  \n",
       "0  0.884646  0.888421  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg\n",
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1f. Summary of results for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment_name                        model_name  \\\n",
       "0        Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1         Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2  Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3           Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "1        0.947981       0.952795         0.912703        0.940054   \n",
       "2        0.945087       0.896552         0.941176        0.739130   \n",
       "3        0.942526       0.944763         0.880729        0.882845   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "1      0.888628     0.864662  0.900505  0.900783   \n",
       "2      0.810127     0.850000  0.870748  0.790698   \n",
       "3      0.888597     0.894068  0.884646  0.888421   \n",
       "\n",
       "                                      hyperparameters  \n",
       "0   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1  {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_lr = pd.read_csv('models/metrics.csv')\n",
    "display(tuned_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Algorithm 2: PCA + Logistic Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn PCA\n",
    "from sklearn.decomposition import PCA\n",
    "#grid search for pca, standardscaler and logistic regression using make_pipeline\n",
    "def grid_search_pca_lr(x_train, y_train):\n",
    "    ''' Function to grid search for PCA, StandardScaler and Logistic Regression using make_pipeline '''\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), PCA(), LogisticRegression())\n",
    "   \n",
    "    param_grid = {'pca__n_components': [2, 3, 4, 5, 6, 7, 8, 9, 10,20,30,50,60],\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'logisticregression__penalty': ['l1', 'l2']}\n",
    "    \n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=5, return_train_score=True)   \n",
    "    grid_search.fit(x_train, y_train)\n",
    "   \n",
    "    best_params = grid_search.best_params_    \n",
    "    display(best_params)\n",
    "\n",
    "    return grid_search, best_params\n",
    "\n",
    "\n",
    "def fit_using_best_params_pca_lr(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "   \n",
    "    best_estimator = grid_search.best_estimator_   \n",
    "    best_estimator.fit(x_train, y_train)    \n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence for pca, standardscaler and logistic regression using make_pipeline\n",
    "def run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for PCA, StandardScaler and Logistic Regression using make_pipeline '''\n",
    "\n",
    "    grid_search, best_params = grid_search_pca_lr(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_pca_lr(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'PCA + LR {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "  \n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    " \n",
    "    model_name = f'models/{set_name}-pca-lr.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "  \n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "  \n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models/metrics.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b. Run PCA + LR sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 100,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 10}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         experiment_name                model_name  train_accuracy  \\\n",
       "0  PCA + LR senate seats  models/senate-pca-lr.pkl        0.947368   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.917031         0.830882        0.736842      0.818841     0.756757   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.824818  0.746667   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c. Run PCA + LR sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 60}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.88687</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment_name               model_name  train_accuracy  \\\n",
       "0  PCA + LR house seats  models/house-pca-lr.pkl        0.938665   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.945342         0.882216        0.897698       0.88687     0.879699   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.884537  0.888608   \n",
       "\n",
       "                                                                               hyperparameters  \n",
       "0  {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d. Run PCA + LR sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 30}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_name                      model_name  \\\n",
       "0  PCA + LR presidential seats  models/presidential-pca-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950867       0.896552         0.930556        0.761905   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.848101          0.8  0.887417  0.780488   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e. Run PCA + LR sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1000,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR all seats</td>\n",
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_name             model_name  train_accuracy  test_accuracy  \\\n",
       "0  PCA + LR all seats  models/all-pca-lr.pkl        0.934576       0.935383   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.858312        0.853659      0.881766     0.889831  0.869881   \n",
       "\n",
       "    test_f1  \\\n",
       "0  0.871369   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f. Summary of results for PCA + LR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment_name                        model_name  \\\n",
       "0        Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1         Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2  Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3           Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                   PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                    PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6             PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                      PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "1        0.947981       0.952795         0.912703        0.940054   \n",
       "2        0.945087       0.896552         0.941176        0.739130   \n",
       "3        0.942526       0.944763         0.880729        0.882845   \n",
       "4        0.947368       0.917031         0.830882        0.736842   \n",
       "5        0.938665       0.945342         0.882216        0.897698   \n",
       "6        0.950867       0.896552         0.930556        0.761905   \n",
       "7        0.934576       0.935383         0.858312        0.853659   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "1      0.888628     0.864662  0.900505  0.900783   \n",
       "2      0.810127     0.850000  0.870748  0.790698   \n",
       "3      0.888597     0.894068  0.884646  0.888421   \n",
       "4      0.818841     0.756757  0.824818  0.746667   \n",
       "5      0.886870     0.879699  0.884537  0.888608   \n",
       "6      0.848101     0.800000  0.887417  0.780488   \n",
       "7      0.881766     0.889831  0.869881  0.871369   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                            {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4  {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5   {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7  {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Random Forest Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#grid search for random forest classifier\n",
    "def grid_search_rf(x_train, y_train):\n",
    "    ''' Function to grid search for Random Forest Classifier '''\n",
    "    #create param grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "    #create grid search\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, return_train_score=True, verbose=1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    #display best params\n",
    "    display(best_params)\n",
    "    return grid_search, best_params\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_rf(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "    #get best estimator\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    #fit best estimator\n",
    "    best_estimator.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence random forest classifier\n",
    "def run_sequence_rf(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Random Forest Classifier '''\n",
    "\n",
    "    grid_search, best_params = grid_search_rf(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_rf(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'Random-Forest {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models/{set_name}-rf.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b. Run Random Forest Classifier sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              experiment_name            model_name  train_accuracy  \\\n",
       "0  Random-Forest senate seats  models/senate-rf.pkl        0.991228   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.925764         0.964286        0.763158      0.978261     0.783784   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.971223  0.773333   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c. Run Random Forest Classifier sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest house seats</td>\n",
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.96087</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             experiment_name           model_name  train_accuracy  \\\n",
       "0  Random-Forest house seats  models/house-rf.pkl        0.965683   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0        0.96087         0.922595        0.928571      0.950176     0.912281   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.936183  0.920354   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d. Run Random Forest Classifier sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.91954</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    experiment_name                  model_name  \\\n",
       "0  Random-Forest presidential seats  models/presidential-rf.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.979769        0.91954         0.973684        0.842105   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.936709          0.8  0.954839  0.820513   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3e. Run Random Forest Classifier sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest all seats</td>\n",
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.89282</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           experiment_name         model_name  train_accuracy  test_accuracy  \\\n",
       "0  Random-Forest all seats  models/all-rf.pkl        0.965072       0.946326   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.923795        0.877301      0.936416     0.908898  0.930063   \n",
       "\n",
       "   test_f1  \\\n",
       "0  0.89282   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random-Forest house seats</td>\n",
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random-Forest all seats</td>\n",
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.892820</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           experiment_name                        model_name  \\\n",
       "0         Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1          Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2   Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3            Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                    PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                     PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6              PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                       PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "8               Random-Forest senate seats              models/senate-rf.pkl   \n",
       "9                Random-Forest house seats               models/house-rf.pkl   \n",
       "10        Random-Forest presidential seats        models/presidential-rf.pkl   \n",
       "11                 Random-Forest all seats                 models/all-rf.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0         0.950658       0.917031         0.854962        0.736842   \n",
       "1         0.947981       0.952795         0.912703        0.940054   \n",
       "2         0.945087       0.896552         0.941176        0.739130   \n",
       "3         0.942526       0.944763         0.880729        0.882845   \n",
       "4         0.947368       0.917031         0.830882        0.736842   \n",
       "5         0.938665       0.945342         0.882216        0.897698   \n",
       "6         0.950867       0.896552         0.930556        0.761905   \n",
       "7         0.934576       0.935383         0.858312        0.853659   \n",
       "8         0.991228       0.925764         0.964286        0.763158   \n",
       "9         0.965683       0.960870         0.922595        0.928571   \n",
       "10        0.979769       0.919540         0.973684        0.842105   \n",
       "11        0.965072       0.946326         0.923795        0.877301   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "0       0.811594     0.756757  0.832714  0.746667   \n",
       "1       0.888628     0.864662  0.900505  0.900783   \n",
       "2       0.810127     0.850000  0.870748  0.790698   \n",
       "3       0.888597     0.894068  0.884646  0.888421   \n",
       "4       0.818841     0.756757  0.824818  0.746667   \n",
       "5       0.886870     0.879699  0.884537  0.888608   \n",
       "6       0.848101     0.800000  0.887417  0.780488   \n",
       "7       0.881766     0.889831  0.869881  0.871369   \n",
       "8       0.978261     0.783784  0.971223  0.773333   \n",
       "9       0.950176     0.912281  0.936183  0.920354   \n",
       "10      0.936709     0.800000  0.954839  0.820513   \n",
       "11      0.936416     0.908898  0.930063  0.892820   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                             {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5    {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6   {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7   {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "9             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10            {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "11            {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithm 4: Ensemble Gradient Boosting Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#grid search for gradient boosting classifier\n",
    "def grid_search_gbc(x_train, y_train):\n",
    "    ''' Function to grid search for Gradient Boosting Classifier '''\n",
    "    #create param grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['friedman_mse', 'mse', 'mae']\n",
    "    }\n",
    "    #create grid search\n",
    "    grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, return_train_score=True, verbose=1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    #display best params\n",
    "    display(best_params)\n",
    "    return grid_search, best_params\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_gbc(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "    #get best estimator\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    #fit best estimator\n",
    "    best_estimator.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence gradient boosting classifier\n",
    "def run_sequence_gbc(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Gradient Boosting Classifier '''\n",
    "\n",
    "    grid_search, best_params = grid_search_gbc(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_gbc(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'Gradient-Boosting {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models/{set_name}-gbc.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b. Run Ensemble Gradient Boosting Classifier sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
       "      <td>models/senate-gbc.pkl</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  experiment_name             model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting senate seats  models/senate-gbc.pkl        0.997807   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.934498         0.992754        0.789474      0.992754     0.810811   \n",
       "\n",
       "   train_f1  test_f1  \\\n",
       "0  0.992754      0.8   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c. Run Ensemble Gradient Boosting Classifier sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models/house-gbc.pkl</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.961491</td>\n",
       "      <td>0.996487</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_name            model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting house seats  models/house-gbc.pkl        0.998447   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.961491         0.996487          0.9202      0.997655     0.924812   \n",
       "\n",
       "   train_f1  test_f1  \\\n",
       "0  0.997071   0.9225   \n",
       "\n",
       "                                                                              hyperparameters  \n",
       "0  {'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d. Run Ensemble Gradient Boosting Classifier sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        experiment_name                   model_name  \\\n",
       "0  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.942529              1.0        0.857143   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0          0.9       1.0  0.878049   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e. Run Ensemble Gradient Boosting Classifier sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.99987</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_name          model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting all seats  models/all-gbc.pkl         0.99987   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.952579              1.0        0.884848      0.999475     0.927966   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.999737  0.905895   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random-Forest house seats</td>\n",
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random-Forest all seats</td>\n",
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.892820</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
       "      <td>models/senate-gbc.pkl</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models/house-gbc.pkl</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.961491</td>\n",
       "      <td>0.996487</td>\n",
       "      <td>0.920200</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           experiment_name                        model_name  \\\n",
       "0         Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1          Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2   Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3            Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                    PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                     PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6              PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                       PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "8               Random-Forest senate seats              models/senate-rf.pkl   \n",
       "9                Random-Forest house seats               models/house-rf.pkl   \n",
       "10        Random-Forest presidential seats        models/presidential-rf.pkl   \n",
       "11                 Random-Forest all seats                 models/all-rf.pkl   \n",
       "12          Gradient-Boosting senate seats             models/senate-gbc.pkl   \n",
       "13           Gradient-Boosting house seats              models/house-gbc.pkl   \n",
       "14    Gradient-Boosting presidential seats       models/presidential-gbc.pkl   \n",
       "15             Gradient-Boosting all seats                models/all-gbc.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0         0.950658       0.917031         0.854962        0.736842   \n",
       "1         0.947981       0.952795         0.912703        0.940054   \n",
       "2         0.945087       0.896552         0.941176        0.739130   \n",
       "3         0.942526       0.944763         0.880729        0.882845   \n",
       "4         0.947368       0.917031         0.830882        0.736842   \n",
       "5         0.938665       0.945342         0.882216        0.897698   \n",
       "6         0.950867       0.896552         0.930556        0.761905   \n",
       "7         0.934576       0.935383         0.858312        0.853659   \n",
       "8         0.991228       0.925764         0.964286        0.763158   \n",
       "9         0.965683       0.960870         0.922595        0.928571   \n",
       "10        0.979769       0.919540         0.973684        0.842105   \n",
       "11        0.965072       0.946326         0.923795        0.877301   \n",
       "12        0.997807       0.934498         0.992754        0.789474   \n",
       "13        0.998447       0.961491         0.996487        0.920200   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "0       0.811594     0.756757  0.832714  0.746667   \n",
       "1       0.888628     0.864662  0.900505  0.900783   \n",
       "2       0.810127     0.850000  0.870748  0.790698   \n",
       "3       0.888597     0.894068  0.884646  0.888421   \n",
       "4       0.818841     0.756757  0.824818  0.746667   \n",
       "5       0.886870     0.879699  0.884537  0.888608   \n",
       "6       0.848101     0.800000  0.887417  0.780488   \n",
       "7       0.881766     0.889831  0.869881  0.871369   \n",
       "8       0.978261     0.783784  0.971223  0.773333   \n",
       "9       0.950176     0.912281  0.936183  0.920354   \n",
       "10      0.936709     0.800000  0.954839  0.820513   \n",
       "11      0.936416     0.908898  0.930063  0.892820   \n",
       "12      0.992754     0.810811  0.992754  0.800000   \n",
       "13      0.997655     0.924812  0.997071  0.922500   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                             {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5    {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6   {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7   {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "9             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10            {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "11            {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "12             {'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}  \n",
       "13    {'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "14             {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "15             {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Algorithm 5: Stacking Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#grid search for stacking classifier\n",
    "def grid_search_stacking(x_train, y_train, set=None):\n",
    "    ''' Function to grid search for Stacking Classifier '''\n",
    "    #load models from pkl files senate\n",
    "    model1 = pickle.load(open(f'models/{set}-rf.pkl', 'rb'))\n",
    "    model2 = pickle.load(open(f'models/{set}-gbc.pkl', 'rb'))\n",
    "    model3 = pickle.load(open(f'models/{set}-tuned-lr.pkl', 'rb'))\n",
    "    model4 = pickle.load(open(f'models/{set}-pca-lr.pkl', 'rb'))\n",
    "    #create a list of models\n",
    "    models = [('rf', model1), ('gbc', model2), ('lr', model3), ('pca-lr', model4)]\n",
    "    #create a stacking classifier\n",
    "    stacking = StackingClassifier(estimators=models, final_estimator=LogisticRegression())\n",
    "    #create a dictionary of params\n",
    "    params = {\n",
    "    'final_estimator__C': [0.1, 1, 10, 100, 1000],\n",
    "    'final_estimator__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'final_estimator__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],    \n",
    "    }\n",
    "    #create a grid search\n",
    "    grid_search = GridSearchCV(stacking, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #return grid search and best params\n",
    "    return grid_search, grid_search.best_params_\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_stacking(x_train, y_train, grid_search, set=None):\n",
    "    ''' Function to fit using best params for Stacking Classifier '''\n",
    "    #load models from pkl files\n",
    "    model1 = pickle.load(open(f'models/{set}-rf.pkl', 'rb'))\n",
    "    model2 = pickle.load(open(f'models/{set}-gbc.pkl', 'rb'))\n",
    "    model3 = pickle.load(open(f'models/{set}-tuned-lr.pkl', 'rb'))\n",
    "    model4 = pickle.load(open(f'models/{set}-pca-lr.pkl', 'rb'))\n",
    "    #create a list of models\n",
    "    models = [('rf', model1), ('gbc', model2), ('lr', model3), ('pca-lr', model4)]\n",
    "    #create a stacking classifier\n",
    "    stacking = StackingClassifier(estimators=models, final_estimator=LogisticRegression())\n",
    "    #fit stacking classifier\n",
    "    stacking.fit(x_train, y_train)\n",
    "    #return best estimator and best params\n",
    "    return stacking, grid_search.best_params_\n",
    "\n",
    "#run sequence for stacking classifier\n",
    "def run_sequence_stacking(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Stacking Classifier '''\n",
    "    #grid search\n",
    "    grid_search, best_params = grid_search_stacking(x_train, y_train, set=set_name)\n",
    "    #fit using best params\n",
    "    best_estimator, best_params = fit_using_best_params_stacking(x_train, y_train, grid_search, set=set_name)\n",
    "    #predict on train and test\n",
    "    y_train_pred = best_estimator.predict(x_train)\n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "    #get metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary of metrics\n",
    "    metrics = {\n",
    "    'experiment_name': f'Stacking {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models/{set_name}-stacking.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b. Run Stacking Algorithm sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         experiment_name                  model_name  train_accuracy  \\\n",
       "0  Stacking senate seats  models/senate-stacking.pkl        0.973684   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.938865         0.931818        0.828571      0.891304     0.783784   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.911111  0.805556   \n",
       "\n",
       "                                                                                    hyperparameters  \n",
       "0  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c. Run Stacking Algorithm sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        experiment_name                 model_name  train_accuracy  \\\n",
       "0  Stacking house seats  models/house-stacking.pkl        0.980745   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.963354         0.965842        0.938144      0.961313     0.912281   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.963572  0.925032   \n",
       "\n",
       "                                                                                  hyperparameters  \n",
       "0  {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5d. Run Stacking Algorithm sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking presidential seats</td>\n",
       "      <td>models/presidential-stacking.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_name                        model_name  \\\n",
       "0  Stacking presidential seats  models/presidential-stacking.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.979769       0.931034         0.986486            0.85   \n",
       "\n",
       "   train_recall  test_recall  train_f1  test_f1  \\\n",
       "0      0.924051         0.85  0.954248     0.85   \n",
       "\n",
       "                                                                                       hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'lbfgs'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5e. Run Stacking Algorithm sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking all seats</td>\n",
       "      <td>models/all-stacking.pkl</td>\n",
       "      <td>0.985794</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.972675</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.971399</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      experiment_name               model_name  train_accuracy  test_accuracy  \\\n",
       "0  Stacking all seats  models/all-stacking.pkl        0.985794       0.952058   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.970126        0.889344      0.972675     0.919492  0.971399   \n",
       "\n",
       "    test_f1  \\\n",
       "0  0.904167   \n",
       "\n",
       "                                                                                     hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv('models/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['segment'] = metrics['experiment_name'].apply(lambda x: 'senate' if 'senate' in x else 'house' if 'house' in x else 'presidential' if 'presidential' in x else 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "      <td>presidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "      <td>senate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name                   model_name  \\\n",
       "17                  Stacking house seats    models/house-stacking.pkl   \n",
       "15           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "14  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "16                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "17        0.980745       0.963354         0.965842        0.938144   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "16        0.973684       0.938865         0.931818        0.828571   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "17      0.961313     0.912281  0.963572  0.925032   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "16      0.891304     0.783784  0.911111  0.805556   \n",
       "\n",
       "                                                                                     hyperparameters  \\\n",
       "17    {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}   \n",
       "15                 {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}   \n",
       "14                 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}   \n",
       "16  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}   \n",
       "\n",
       "         segment  \n",
       "17         house  \n",
       "15           all  \n",
       "14  presidential  \n",
       "16        senate  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest performing model in each segment based on test accuracy\n",
    "metrics.sort_values(by='test_accuracy', ascending=False).groupby('segment').head(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "      <td>presidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "      <td>senate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         experiment_name                   model_name  \\\n",
       "17                  Stacking house seats    models/house-stacking.pkl   \n",
       "15           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "14  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "16                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "17        0.980745       0.963354         0.965842        0.938144   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "16        0.973684       0.938865         0.931818        0.828571   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "17      0.961313     0.912281  0.963572  0.925032   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "16      0.891304     0.783784  0.911111  0.805556   \n",
       "\n",
       "                                                                                     hyperparameters  \\\n",
       "17    {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}   \n",
       "15                 {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}   \n",
       "14                 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}   \n",
       "16  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}   \n",
       "\n",
       "         segment  \n",
       "17         house  \n",
       "15           all  \n",
       "14  presidential  \n",
       "16        senate  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest performing model in each segment based on f1y\n",
    "metrics.sort_values(by='test_f1', ascending=False).groupby('segment').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation to baseline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(2,2, figsize=(15,10))\n",
    "sns.countplot(df_senate['label'], ax=ax[0,0])\n",
    "sns.countplot(df_house['label'], ax=ax[0,1])\n",
    "sns.countplot(df_presidential['label'], ax=ax[1,0])\n",
    "sns.countplot(df['label'], ax=ax[1,1])\n",
    "ax[0,0].set_title('Senate')\n",
    "ax[0,1].set_title('House')\n",
    "ax[1,0].set_title('Presidential')\n",
    "ax[1,1].set_title('All')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baselines: {'senate': 0.8466257668711656, 'house': 0.7385093167701864, 'presidential': 0.7713625866050808, 'all': 0.7523978315262719}\n"
     ]
    }
   ],
   "source": [
    "#save all precentage of label 0 and label 1 in each segment\n",
    "senate_0 = df_senate[df_senate['label']==0].shape[0]/df_senate.shape[0]\n",
    "senate_1 = df_senate[df_senate['label']==1].shape[0]/df_senate.shape[0]\n",
    "house_0 = df_house[df_house['label']==0].shape[0]/df_house.shape[0]\n",
    "house_1 = df_house[df_house['label']==1].shape[0]/df_house.shape[0]\n",
    "presidential_0 = df_presidential[df_presidential['label']==0].shape[0]/df_presidential.shape[0]\n",
    "presidential_1 = df_presidential[df_presidential['label']==1].shape[0]/df_presidential.shape[0]\n",
    "all_0 = df[df['label']==0].shape[0]/df.shape[0]\n",
    "all_1 = df[df['label']==1].shape[0]/df.shape[0]\n",
    "\n",
    "#save all 0 classes to dictionary\n",
    "dict_0 = {'senate': senate_0, 'house': house_0, 'presidential': presidential_0, 'all': all_0}\n",
    "\n",
    "print(f'baselines: {dict_0}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot all 0 classes\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(dict_0.keys(), dict_0.values())\n",
    "plt.title('Baseline ')\n",
    "#add labels to bars\n",
    "for index, value in enumerate(dict_0.values()):\n",
    "    plt.text(index, value, str(round(value, 2)))\n",
    "y_axis_title = 'Percentage of 0 class'\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our best models to a zero-rate classifier (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_accuracy = metrics.sort_values(by='test_accuracy', ascending=False).groupby('segment').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_models_accuracy['baseline'] = best_models_accuracy['segment'].map(dict_0)\n",
    "\n",
    "#calculate test accuracy improvement over baseline\n",
    "best_models_accuracy['test_acc_impr'] = best_models_accuracy['test_accuracy'] - best_models_accuracy['baseline']\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr']/best_models_accuracy['baseline']\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr']*100\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr_pct'].apply(lambda x: round(x, 2))\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr_pct'].apply(lambda x: str(x)+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>segment</th>\n",
       "      <th>baseline</th>\n",
       "      <th>test_acc_impr</th>\n",
       "      <th>test_acc_impr_pct</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>house</td>\n",
       "      <td>0.738509</td>\n",
       "      <td>0.224845</td>\n",
       "      <td>22.48%</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.961313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>all</td>\n",
       "      <td>0.752398</td>\n",
       "      <td>0.200182</td>\n",
       "      <td>20.02%</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>presidential</td>\n",
       "      <td>0.771363</td>\n",
       "      <td>0.171166</td>\n",
       "      <td>17.12%</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>senate</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.092239</td>\n",
       "      <td>9.22%</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        experiment_name                   model_name  \\\n",
       "0                  Stacking house seats    models/house-stacking.pkl   \n",
       "1           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "2  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "3                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "        segment  baseline  test_acc_impr test_acc_impr_pct  test_accuracy  \\\n",
       "0         house  0.738509       0.224845            22.48%       0.963354   \n",
       "1           all  0.752398       0.200182            20.02%       0.952579   \n",
       "2  presidential  0.771363       0.171166            17.12%       0.942529   \n",
       "3        senate  0.846626       0.092239             9.22%       0.938865   \n",
       "\n",
       "    test_f1  test_precision  test_recall  train_accuracy  train_f1  \\\n",
       "0  0.925032        0.938144     0.912281        0.980745  0.963572   \n",
       "1  0.905895        0.884848     0.927966        0.999870  0.999737   \n",
       "2  0.878049        0.857143     0.900000        1.000000  1.000000   \n",
       "3  0.805556        0.828571     0.783784        0.973684  0.911111   \n",
       "\n",
       "   train_precision  train_recall  \n",
       "0         0.965842      0.961313  \n",
       "1         1.000000      0.999475  \n",
       "2         1.000000      1.000000  \n",
       "3         0.931818      0.891304  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_models_accuracy = best_models_accuracy[['experiment_name', 'model_name', 'segment', 'baseline', 'test_acc_impr', 'test_acc_impr_pct', 'test_accuracy', 'test_f1', 'test_precision', 'test_recall', 'train_accuracy', 'train_f1', 'train_precision', 'train_recall']]\n",
    "best_models_accuracy.reset_index(drop=True, inplace=True)\n",
    "best_models_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot test accuracy improvement over baseline add test_accr_impr to baseline\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(x='segment', y='test_acc_impr', data=best_models_accuracy, ax=ax)\n",
    "ax.set_title('Test Accuracy Improvement over Baseline')\n",
    "\n",
    "for i, v in enumerate(best_models_accuracy['experiment_name']):\n",
    "    ax.text(i-.25, best_models_accuracy['test_acc_impr'][i]+.001, v, fontsize=10)\n",
    "\n",
    " \n",
    "for i, v in enumerate(best_models_accuracy['test_acc_impr_pct']):\n",
    "    ax.text(i-.50, best_models_accuracy['test_acc_impr'][i]+.0010, v, fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d05d3ed20d17a9c8ee84c44b7d541b39e2d1ba1a844cb5793cf52df81ef9f2c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
