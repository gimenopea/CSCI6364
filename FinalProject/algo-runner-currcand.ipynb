{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Experiment Setup**\n",
    "**There are 5 algorithms applied in our dataset:**\n",
    "1. Tuned logistic regression\n",
    "2. Principal Component Analysis and Logistic Regression\n",
    "3. Random Forest Classifier \n",
    "4. Ensemble Gradient Boosting Classifier with tuned parameters\n",
    "5. Stacking Algorithm with a logistic regression meta model (final classifier)\n",
    "\n",
    "**These 5 algorithms are applied in 4 areas so that we can predict election winner outcomes in:**\n",
    "\n",
    " 1.  Senate Seats\n",
    " 2.  House Seats\n",
    " 3.  Presidential Sets\n",
    " 4.  All Seats (Senate, House, Presidential)\n",
    " \n",
    " **Algorithms 1 - 4 will produce 16 .pkl model files as shown below.**\n",
    " \n",
    " **Algorithm 5 will produce 1 Stacking Algorithm model using the 16 .pkl models and produce 4 .pkl model files for a total of 20 .pkl model files.**\n",
    "\n",
    " **All algorithms will use cross validation (k=5) to determine the best parameters for each model.**\n",
    "\n",
    " **All algorithms will use a holdout test set to determine the accuracy and f1 score. We will base our final model selection highest accuracy and f1 score.**\n",
    " \n",
    "\n",
    "|Model #|Model Filename|Model Description\n",
    "|--|--|--\n",
    "|1|senate-tuned-lr|logistic regression on senate candidates with tuned hyperparameters\n",
    "|2|house-tuned-lr|logistic regression on house candidates with tuned hyperparameters\n",
    "|3|pres-tuned-lr|logistic regression on presidential candidates with tuned hyperparameters\n",
    "|4|all-tuned-lr|logistic regression on all candidates with tuned hyperparameters\n",
    "|5|senate-pca-lr|pca + logistic regression on senate candidates\n",
    "|6|house-pca-lr|pca + logistic regression on house candidates\n",
    "|7|pres-pca-lr|pca + logistic regression on presidential candidates\n",
    "|8|all-pca-lr|pca + logistic regression on all candidates\n",
    "|9|senate-rf|random forest classificer on senate candidates\n",
    "|10|house-rf|random forest classificer on senate candidates\n",
    "|11|pres-rf|random forest classificer on senate candidates\n",
    "|12|all-rf|random forest classificer on senate candidates\n",
    "|13|senate-gb|gradient boosting algo on senate candidates\n",
    "|14|house-gb|gradient boosting algo on senate candidates\n",
    "|15|pres-gb|gradient boosting algo on senate candidates\n",
    "|16|all-gb|gradient boosting algo on senate candidates\n",
    "\n",
    "\n",
    "**Comparison to baseline**\n",
    "\n",
    "At the end of this notebook, we will compare our model to a classifier that only predicts on the majority class. This will be our baseline metric. We will prove that our model is better than the baseline model by showing that our model has a higher accuracy than the baseline model\n",
    "\n",
    "\n",
    "**Libraries used**\n",
    "\n",
    "- numpy for numerical analysis\n",
    "- pandas for data manipulation\n",
    "- matplotlib for data visualization\n",
    "- seaborn for data visualization\n",
    "- sklearn for machine learning algorithms\n",
    "- pickle for saving models\n",
    "\n",
    "**code snippet attribution**\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html : for grid search implementation\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html :  for lr implementation\n",
    "- https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74:  for rf grid search implementation and the basis for gradient boosting implementation\n",
    "- https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/ : for stacking implementation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of flattened feature engineered data can be referenced here:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 1,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv('data/all_features_candidate_summary_with_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 10,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter only to current candidates\n",
    "df = df[df['CurrCand'] == 'Y']"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 2,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#run function for data pre-processing\n",
    "def pre_process(df):   \n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['run_for_state','run_for_district','cand_party'])\n",
    "    #split x and y\n",
    "    y = df['label']\n",
    "    x = df.drop(['label'], axis=1)\n",
    "\n",
    "    #remove collinear and redundant features as they can skew our Beta coefficients variables\n",
    "    #if x has columned called 'Unnamed: 0'\n",
    "    if 'Unnamed: 0' in x.columns:\n",
    "        x = x.drop(['Unnamed: 0','CycleCands_x','curr_cand','RepeatDonorCount','CycleCands_y','challenger','FemaleDonorCount','TotalGiftAvg.1','open_office'], axis=1)\n",
    "    else:\n",
    "        x = x.drop(['curr_cand','RepeatDonorCount','challenger','FemaleDonorCount','TotalGiftAvg.1'], axis=1)\n",
    "\n",
    "    #drop non numeric columns in x\n",
    "    x = x.select_dtypes(include=['float64','int64','uint8','int32'])\n",
    "      \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 3,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "df_senate = df[df['senate_seat'] == 1].copy()\n",
    "df_presidential = df[df['presidential_seat'] == 1].copy()\n",
    "df_house = df[df['house_seat'] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 4,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Senate seat row count:  492\n",
      "Presidential seat row count:  213\n",
      "House seat row count:  4113\n",
      "All row count:  4806\n"
=======
      "Senate seat row count:  1141\n",
      "Presidential seat row count:  433\n",
      "House seat row count:  8050\n",
      "All row count:  9592\n"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print row count for each dataframe\n",
    "print('Senate seat row count: ', df_senate.shape[0])\n",
    "print('Presidential seat row count: ', df_presidential.shape[0])\n",
    "print('House seat row count: ', df_house.shape[0])\n",
    "print('All row count: ', df.shape[0])\n",
    "%matplotlib inline \n",
    "\n",
    "#plot the distribution of the labels\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,5))\n",
    "sns.countplot(x='label', data=df_senate, ax=ax[0])\n",
    "sns.countplot(x='label', data=df_presidential, ax=ax[1])\n",
    "sns.countplot(x='label', data=df_house, ax=ax[2])\n",
    "#show percentage of labels in the plot\n",
    "for i in range(3):\n",
    "    total = len(df_senate) if i == 0 else len(df_presidential) if i == 1 else len(df_house)\n",
    "    for p in ax[i].patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height()/total)\n",
    "        x = p.get_x() + p.get_width() / 2 - 0.05\n",
    "        y = p.get_y() + p.get_height()\n",
    "        ax[i].annotate(percentage, (x, y))\n",
    "ax[0].set_title('Senate')\n",
    "ax[1].set_title('Presidential')\n",
    "ax[2].set_title('House')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Tuned Logistic Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a. Helper functions to run this task**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 5,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions for this task\n",
    "def plot_correlation(x,y, set_name=None):\n",
    "    ''' Function to plot correlation between features and labels '''\n",
    "    correlation = x.corrwith(y)\n",
    "    correlation = correlation.sort_values(ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.barh(correlation.index, correlation.values)   \n",
    "    plt.title(f'Correlation of Features with Target on {set_name} seats')\n",
    "    plt.xlabel('Correlation')\n",
    "    plt.savefig(f'plots/1-{set_name}-correlation-lr.png')\n",
    "    #plt.show()\n",
    "\n",
    "def grid_search_tuned_lr(x_train, y_train, cv=5):\n",
    "    ''' Function to perform grid search on logistic regression '''\n",
    "    logreg = LogisticRegression(max_iter=1000, tol=.001)\n",
    "    std_scaler = StandardScaler()\n",
    "    pipeline = make_pipeline(std_scaler, logreg)\n",
    "\n",
    "    params = [\n",
    "  {'logisticregression__penalty': ['l1'], 'logisticregression__solver': ['liblinear', 'sag','saga'], 'logisticregression__C': [0.01, 0.1, 1, 10], 'logisticregression__class_weight': ['balanced', None]},\n",
    "  {'logisticregression__penalty': ['l2'], 'logisticregression__solver': ['lbfgs','newton-cg'],'logisticregression__C': [0.01, 0.1, 1, 10], 'logisticregression__class_weight': ['balanced', None]},\n",
    " ]\n",
    "    \n",
    "\n",
    "    grid = GridSearchCV(pipeline, param_grid=params, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "    grid.fit(x_train, y_train)\n",
    "    print('best score: ', grid.best_score_)\n",
    "    print('best params: ', grid.best_params_)\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def fit_using_best_params_lr(x_train, y_train, grid_search = None):\n",
    "    ''' function to fit the model using the best params from grid search '''\n",
    "    if grid_search is not None:\n",
    "        best_c = grid_search.best_params_['logisticregression__C']\n",
    "        best_class_weight = grid_search.best_params_['logisticregression__class_weight']\n",
    "        best_penalty = grid_search.best_params_['logisticregression__penalty']\n",
    "        best_solver = grid_search.best_params_['logisticregression__solver']\n",
    "        \n",
    "    #save best params to a dictionary\n",
    "    best_params = {'C':best_c, 'class_weight':best_class_weight, 'penalty':best_penalty}\n",
    "    pipeline = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000, C=best_c, class_weight=best_class_weight, solver=best_solver,penalty=best_penalty, tol=.001))\n",
    "    pipeline.fit(x_train, y_train)  \n",
    "    \n",
    "    return pipeline, best_params\n",
    "    \n",
    "\n",
    "def get_feature_importance(pipeline, x_val, set_name = None):\n",
    "    ''' Function to plot feature importance after logistic regression '''\n",
    "   \n",
    "    feature_importance = pipeline.steps[1][1].coef_[0]\n",
    "\n",
    "    feature_names = x_val.columns\n",
    "    feature_importance_df = pd.DataFrame({'feature':feature_names, 'importance':feature_importance})\n",
    "    #sort by importance\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.barh(feature_importance_df['feature'], feature_importance_df['importance'])\n",
    "    plt.title(f'Feature Importance on {set_name} seats')\n",
    "    plt.xlabel('Importance')     \n",
    "    plt.savefig(f'plots/3-{set_name}-feature-importance-lr.png')\n",
    "    #plt.show() \n",
    "    return feature_importance\n",
    "\n",
    "\n",
    "#evaluate model function\n",
    "def evaluate_model(model, x_train, y_train, x_val, y_val, set_name = None,best_params = None):\n",
    "    ''' Function to evaluate model on train and validation set '''   \n",
    "    #save accuracy, precision, recall, f1 score\n",
    "    train_accuracy = model.score(x_train, y_train)\n",
    "    val_accuracy = model.score(x_val, y_val)\n",
    "\n",
    "    #predict on train and validation set\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_val_pred = model.predict(x_val)\n",
    "\n",
    "    #recall\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    val_recall = recall_score(y_val, y_val_pred)\n",
    "\n",
    "    #precision\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    val_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    #f1 score\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)  \n",
    "\n",
    "    #save all metrics and best params to a dataframe\n",
    "    metrics_df = pd.DataFrame({'experiment_name': f'Logistic Regression {set_name} seats', \n",
    "    'train_accuracy':[train_accuracy], \n",
    "    'test_accuracy':[val_accuracy], \n",
    "    'train_precision':[train_precision], \n",
    "    'test_precision':[val_precision],\n",
    "    'train_recall':[train_recall], \n",
    "    'test_recall':[val_recall],      \n",
    "    'train_f1':[train_f1], \n",
    "    'test_f1':[val_f1],\n",
    "    'hyperparameters':[best_params]})    \n",
    "    return metrics_df\n",
    "\n",
    "def run_sequence_lr(x_train, y_train, x_val, y_val, set_name = None):\n",
    "    #get correlation\n",
    "    #correlation = plot_correlation(x_train, y_train, set_name)\n",
    "    #label distribution\n",
    "    #label_distribution(y_train, set_name)\n",
    "    #grid search\n",
    "    grid_search = grid_search_tuned_lr(x_train, y_train)\n",
    "    #fit using best params\n",
    "    model, best_params = fit_using_best_params_lr(x_train, y_train, grid_search)    \n",
    "    #get feature importance\n",
    "    feature_importance = get_feature_importance(model, x_train, set_name)\n",
    "    #evaluate model\n",
    "    metrics_df = evaluate_model(model, x_train, y_train, x_val, y_val, set_name=set_name, best_params=best_params)\n",
    "    #save model to pickle\n",
    "    model_name = f'models-currcand/{set_name}-tuned-lr.pkl'\n",
    "    pickle.dump(model, open(model_name, 'wb'))\n",
    "    #add column to metrics_df called model_name on index 1\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #display metrics_df dataframe\n",
    "    display(metrics_df)     \n",
    "    metrics_df.to_csv('models-currcand/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['experiment_name', \n",
    "'model_name', 'train_accuracy', \n",
    "'test_accuracy', 'train_precision', 'test_precision', 'train_recall', 'test_recall', 'train_f1', 'test_f1', 'hyperparameters'])\n",
    "filename = f'models-currcand/metrics.csv'\n",
    "metrics_df.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b. Run Logistic Regression sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 6,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "best score:  0.8802661473547551\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    experiment_name                           model_name  \\\n",
       "0  Logistic Regression senate seats  models-currcand/senate-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.885496       0.838384         0.786585        0.763158   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.928058     0.805556  0.851485  0.783784   \n",
       "\n",
       "                                           hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg \n",
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c. Run Logistic Regression sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.901823708206687\n",
=======
      "best score:  0.948465741908365\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.919806</td>\n",
       "      <td>0.903981</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.915777</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>Logistic Regression senate seats</td>\n",
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    experiment_name                           model_name  \\\n",
       "0  Logistic Regression senate seats  models-currcand/senate-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg \n",
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c. Run Logistic Regression sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9475155279503106\n",
      "best params:  {'logisticregression__C': 0.01, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   experiment_name                          model_name  \\\n",
       "0  Logistic Regression house seats  models-currcand/house-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
<<<<<<< HEAD
       "0        0.906991       0.919806         0.903981        0.906542   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.915777     0.937198  0.909841  0.921615   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
=======
       "0        0.947981       0.952795         0.912703        0.940054   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.888628     0.864662  0.900505  0.900783   \n",
       "\n",
       "                                      hyperparameters  \n",
       "0  {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg \n",
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d. Run Logistic Regression sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 8,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "best score:  0.8764705882352942\n",
      "best params:  {'logisticregression__C': 1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n"
=======
      "best score:  0.9364389233954451\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': None, 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'saga'}\n"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
       "      <td>models-currcand/presidential-tuned-lr.pkl</td>\n",
<<<<<<< HEAD
       "      <td>0.947059</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment_name  \\\n",
       "0  Logistic Regression presidential seats   \n",
       "\n",
       "                                  model_name  train_accuracy  test_accuracy  \\\n",
<<<<<<< HEAD
       "0  models-currcand/presidential-tuned-lr.pkl        0.947059       0.883721   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.939024        0.882353      0.950617     0.833333  0.944785   \n",
       "\n",
       "    test_f1                                  hyperparameters  \n",
       "0  0.857143  {'C': 1, 'class_weight': None, 'penalty': 'l1'}  "
=======
       "0  models-currcand/presidential-tuned-lr.pkl        0.945087       0.896552   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.941176         0.73913      0.810127         0.85  0.870748   \n",
       "\n",
       "    test_f1                                    hyperparameters  \n",
       "0  0.790698  {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg\n",
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1e. Run Logistic Regression sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score:  0.9008774246857391\n",
      "best params:  {'logisticregression__C': 0.1, 'logisticregression__class_weight': 'balanced', 'logisticregression__penalty': 'l1', 'logisticregression__solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
       "      <td>models-currcand/all-tuned-lr.pkl</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.908103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_name                        model_name  \\\n",
       "0  Logistic Regression all seats  models-currcand/all-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.907648       0.883576         0.897646        0.867368   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.918806     0.893709  0.908103  0.880342   \n",
       "\n",
       "                                           hyperparameters  \n",
       "0  {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14020/3468338911.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m69\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_sequence_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14020/3250875449.py\u001b[0m in \u001b[0;36mrun_sequence_lr\u001b[1;34m(x_train, y_train, x_val, y_val, set_name)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m#label_distribution(y_train, set_name)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m#grid search\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_tuned_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;31m#fit using best params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_using_best_params_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14020/3250875449.py\u001b[0m in \u001b[0;36mgrid_search_tuned_lr\u001b[1;34m(x_train, y_train, cv)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best score: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best params: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    820\u001b[0m                     )\n\u001b[0;32m    821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    823\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\pgimeno\\Anaconda3\\envs\\SMHS_WH\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
    }
   ],
   "source": [
    "%matplotlib agg \n",
    "%matplotlib agg\n",
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_lr(x_train, y_train, x_val, y_val, 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1f. Summary of results for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.919806</td>\n",
       "      <td>0.903981</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.915777</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-tuned-lr.pkl</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.908103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                          experiment_name  \\\n",
       "0        Logistic Regression senate seats   \n",
       "1         Logistic Regression house seats   \n",
       "2  Logistic Regression presidential seats   \n",
       "3           Logistic Regression all seats   \n",
       "\n",
       "                                  model_name  train_accuracy  test_accuracy  \\\n",
       "0        models-currcand/senate-tuned-lr.pkl        0.885496       0.838384   \n",
       "1         models-currcand/house-tuned-lr.pkl        0.906991       0.919806   \n",
       "2  models-currcand/presidential-tuned-lr.pkl        0.947059       0.883721   \n",
       "3           models-currcand/all-tuned-lr.pkl        0.907648       0.883576   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.786585        0.763158      0.928058     0.805556  0.851485   \n",
       "1         0.903981        0.906542      0.915777     0.937198  0.909841   \n",
       "2         0.939024        0.882353      0.950617     0.833333  0.944785   \n",
       "3         0.897646        0.867368      0.918806     0.893709  0.908103   \n",
       "\n",
       "    test_f1                                          hyperparameters  \n",
       "0  0.783784  {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "1  0.921615        {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2  0.857143          {'C': 1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3  0.880342  {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  "
=======
       "                          experiment_name                        model_name  \\\n",
       "0        Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1         Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2  Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3           Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "1        0.947981       0.952795         0.912703        0.940054   \n",
       "2        0.945087       0.896552         0.941176        0.739130   \n",
       "3        0.942526       0.944763         0.880729        0.882845   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "1      0.888628     0.864662  0.900505  0.900783   \n",
       "2      0.810127     0.850000  0.870748  0.790698   \n",
       "3      0.888597     0.894068  0.884646  0.888421   \n",
       "\n",
       "                                      hyperparameters  \n",
       "0   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1  {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3   {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_lr = pd.read_csv('models-currcand/metrics.csv')\n",
    "display(tuned_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Algorithm 2: PCA + Logistic Regression\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn PCA\n",
    "from sklearn.decomposition import PCA\n",
    "#grid search for pca, standardscaler and logistic regression using make_pipeline\n",
    "def grid_search_pca_lr(x_train, y_train):\n",
    "    ''' Function to grid search for PCA, StandardScaler and Logistic Regression using make_pipeline '''\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), PCA(), LogisticRegression())\n",
    "   \n",
    "    param_grid = {'pca__n_components': [2, 3, 4, 5, 6, 7, 8, 9, 10,20,30,50,60],\n",
    "    'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'logisticregression__penalty': ['l1', 'l2']}\n",
    "    \n",
    "    grid_search = GridSearchCV(pipe, param_grid, cv=5, return_train_score=True)   \n",
    "    grid_search.fit(x_train, y_train)\n",
    "   \n",
    "    best_params = grid_search.best_params_    \n",
    "    display(best_params)\n",
    "\n",
    "    return grid_search, best_params\n",
    "\n",
    "\n",
    "def fit_using_best_params_pca_lr(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "   \n",
    "    best_estimator = grid_search.best_estimator_   \n",
    "    best_estimator.fit(x_train, y_train)    \n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence for pca, standardscaler and logistic regression using make_pipeline\n",
    "def run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for PCA, StandardScaler and Logistic Regression using make_pipeline '''\n",
    "\n",
    "    grid_search, best_params = grid_search_pca_lr(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_pca_lr(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'PCA + LR {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "  \n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    " \n",
    "    model_name = f'models-currcand/{set_name}-pca-lr.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "  \n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "  \n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models-currcand/metrics.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b. Run PCA + LR sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'logisticregression__C': 0.01,\n",
=======
       "{'logisticregression__C': 100,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 10}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         experiment_name                model_name  train_accuracy  \\\n",
       "0  PCA + LR senate seats  models/senate-pca-lr.pkl        0.947368   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.917031         0.830882        0.736842      0.818841     0.756757   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.824818  0.746667   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c. Run PCA + LR sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 10,\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 60}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>PCA + LR senate seats</td>\n",
       "      <td>models-currcand/senate-pca-lr.pkl</td>\n",
       "      <td>0.898219</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         experiment_name                         model_name  train_accuracy  \\\n",
       "0  PCA + LR senate seats  models-currcand/senate-pca-lr.pkl        0.898219   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.818182         0.861314         0.78125      0.848921     0.694444   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.855072  0.735294   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0  {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c. Run PCA + LR sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models-currcand/house-pca-lr.pkl</td>\n",
       "      <td>0.89848</td>\n",
       "      <td>0.889429</td>\n",
       "      <td>0.886286</td>\n",
       "      <td>0.88361</td>\n",
       "      <td>0.919929</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.902794</td>\n",
       "      <td>0.891018</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}</td>\n",
=======
       "      <td>PCA + LR house seats</td>\n",
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.88687</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "        experiment_name                        model_name  train_accuracy  \\\n",
       "0  PCA + LR house seats  models-currcand/house-pca-lr.pkl         0.89848   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.889429         0.886286         0.88361      0.919929     0.898551   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.902794  0.891018   \n",
       "\n",
       "                                                                               hyperparameters  \n",
       "0  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}  "
=======
       "        experiment_name               model_name  train_accuracy  \\\n",
       "0  PCA + LR house seats  models/house-pca-lr.pkl        0.938665   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.945342         0.882216        0.897698       0.88687     0.879699   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.884537  0.888608   \n",
       "\n",
       "                                                                               hyperparameters  \n",
       "0  {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d. Run PCA + LR sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'logisticregression__C': 0.01,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 6}"
=======
       "{'logisticregression__C': 0.1,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 30}"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-pca-lr.pkl</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}</td>\n",
=======
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "               experiment_name                               model_name  \\\n",
       "0  PCA + LR presidential seats  models-currcand/presidential-pca-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.876471       0.906977         0.833333        0.818182   \n",
       "\n",
       "   train_recall  test_recall  train_f1  test_f1  \\\n",
       "0      0.925926          1.0  0.877193      0.9   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}  "
=======
       "               experiment_name                      model_name  \\\n",
       "0  PCA + LR presidential seats  models/presidential-pca-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950867       0.896552         0.930556        0.761905   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.848101          0.8  0.887417  0.780488   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e. Run PCA + LR sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'logisticregression__C': 0.01,\n",
=======
       "{'logisticregression__C': 1000,\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       " 'logisticregression__penalty': 'l2',\n",
       " 'pca__n_components': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCA + LR all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-pca-lr.pkl</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.866944</td>\n",
       "      <td>0.867446</td>\n",
       "      <td>0.825832</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.868313</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
=======
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "      experiment_name                      model_name  train_accuracy  \\\n",
       "0  PCA + LR all seats  models-currcand/all-pca-lr.pkl        0.895682   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.866944         0.867446        0.825832      0.932425     0.915401   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.898763  0.868313   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
=======
       "      experiment_name             model_name  train_accuracy  test_accuracy  \\\n",
       "0  PCA + LR all seats  models/all-pca-lr.pkl        0.934576       0.935383   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.858312        0.853659      0.881766     0.889831  0.869881   \n",
       "\n",
       "    test_f1  \\\n",
       "0  0.871369   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0  {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_pca_lr(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f. Summary of results for PCA + LR**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.919806</td>\n",
       "      <td>0.903981</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.915777</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-tuned-lr.pkl</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.908103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-pca-lr.pkl</td>\n",
       "      <td>0.898219</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
=======
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-pca-lr.pkl</td>\n",
       "      <td>0.898480</td>\n",
       "      <td>0.889429</td>\n",
       "      <td>0.886286</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.919929</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.902794</td>\n",
       "      <td>0.891018</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}</td>\n",
=======
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-pca-lr.pkl</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}</td>\n",
=======
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-pca-lr.pkl</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.866944</td>\n",
       "      <td>0.867446</td>\n",
       "      <td>0.825832</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.868313</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
=======
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                          experiment_name  \\\n",
       "0        Logistic Regression senate seats   \n",
       "1         Logistic Regression house seats   \n",
       "2  Logistic Regression presidential seats   \n",
       "3           Logistic Regression all seats   \n",
       "4                   PCA + LR senate seats   \n",
       "5                    PCA + LR house seats   \n",
       "6             PCA + LR presidential seats   \n",
       "7                      PCA + LR all seats   \n",
       "\n",
       "                                  model_name  train_accuracy  test_accuracy  \\\n",
       "0        models-currcand/senate-tuned-lr.pkl        0.885496       0.838384   \n",
       "1         models-currcand/house-tuned-lr.pkl        0.906991       0.919806   \n",
       "2  models-currcand/presidential-tuned-lr.pkl        0.947059       0.883721   \n",
       "3           models-currcand/all-tuned-lr.pkl        0.907648       0.883576   \n",
       "4          models-currcand/senate-pca-lr.pkl        0.898219       0.818182   \n",
       "5           models-currcand/house-pca-lr.pkl        0.898480       0.889429   \n",
       "6    models-currcand/presidential-pca-lr.pkl        0.876471       0.906977   \n",
       "7             models-currcand/all-pca-lr.pkl        0.895682       0.866944   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.786585        0.763158      0.928058     0.805556  0.851485   \n",
       "1         0.903981        0.906542      0.915777     0.937198  0.909841   \n",
       "2         0.939024        0.882353      0.950617     0.833333  0.944785   \n",
       "3         0.897646        0.867368      0.918806     0.893709  0.908103   \n",
       "4         0.861314        0.781250      0.848921     0.694444  0.855072   \n",
       "5         0.886286        0.883610      0.919929     0.898551  0.902794   \n",
       "6         0.833333        0.818182      0.925926     1.000000  0.877193   \n",
       "7         0.867446        0.825832      0.932425     0.915401  0.898763   \n",
       "\n",
       "    test_f1  \\\n",
       "0  0.783784   \n",
       "1  0.921615   \n",
       "2  0.857143   \n",
       "3  0.880342   \n",
       "4  0.735294   \n",
       "5  0.891018   \n",
       "6  0.900000   \n",
       "7  0.868313   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0                                        {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "1                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                                {'C': 1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                        {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "4  {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "5    {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}  \n",
       "6   {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}  \n",
       "7   {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
=======
       "                          experiment_name                        model_name  \\\n",
       "0        Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1         Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2  Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3           Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                   PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                    PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6             PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                      PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.950658       0.917031         0.854962        0.736842   \n",
       "1        0.947981       0.952795         0.912703        0.940054   \n",
       "2        0.945087       0.896552         0.941176        0.739130   \n",
       "3        0.942526       0.944763         0.880729        0.882845   \n",
       "4        0.947368       0.917031         0.830882        0.736842   \n",
       "5        0.938665       0.945342         0.882216        0.897698   \n",
       "6        0.950867       0.896552         0.930556        0.761905   \n",
       "7        0.934576       0.935383         0.858312        0.853659   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.811594     0.756757  0.832714  0.746667   \n",
       "1      0.888628     0.864662  0.900505  0.900783   \n",
       "2      0.810127     0.850000  0.870748  0.790698   \n",
       "3      0.888597     0.894068  0.884646  0.888421   \n",
       "4      0.818841     0.756757  0.824818  0.746667   \n",
       "5      0.886870     0.879699  0.884537  0.888608   \n",
       "6      0.848101     0.800000  0.887417  0.780488   \n",
       "7      0.881766     0.889831  0.869881  0.871369   \n",
       "\n",
       "                                                                                hyperparameters  \n",
       "0                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                            {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                             {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4  {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5   {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6  {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7  {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models-currcand/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Random Forest Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#grid search for random forest classifier\n",
    "def grid_search_rf(x_train, y_train):\n",
    "    ''' Function to grid search for Random Forest Classifier '''\n",
    "    #create param grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "    #create grid search\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, return_train_score=True, verbose=1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    #display best params\n",
    "    display(best_params)\n",
    "    return grid_search, best_params\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_rf(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "    #get best estimator\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    #fit best estimator\n",
    "    best_estimator.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence random forest classifier\n",
    "def run_sequence_rf(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Random Forest Classifier '''\n",
    "\n",
    "    grid_search, best_params = grid_search_rf(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_rf(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'Random-Forest {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models-currcand/{set_name}-rf.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models-currcand/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b. Run Random Forest Classifier sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
<<<<<<< HEAD
       " 'max_features': 'auto',\n",
=======
       " 'max_features': 'sqrt',\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-rf.pkl</td>\n",
       "      <td>0.982188</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.952055</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "              experiment_name                     model_name  train_accuracy  \\\n",
       "0  Random-Forest senate seats  models-currcand/senate-rf.pkl        0.982188   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.878788         0.952055           0.875           1.0     0.777778   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.975439  0.823529   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}  "
=======
       "              experiment_name            model_name  train_accuracy  \\\n",
       "0  Random-Forest senate seats  models/senate-rf.pkl        0.991228   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.925764         0.964286        0.763158      0.978261     0.783784   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.971223  0.773333   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3c. Run Random Forest Classifier sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-rf.pkl</td>\n",
       "      <td>0.951672</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.933069</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>0.975682</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.9539</td>\n",
       "      <td>0.934579</td>\n",
=======
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.96087</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "             experiment_name                    model_name  train_accuracy  \\\n",
       "0  Random-Forest house seats  models-currcand/house-rf.pkl        0.951672   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.931956         0.933069        0.904977      0.975682     0.966184   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0    0.9539  0.934579   \n",
=======
       "             experiment_name           model_name  train_accuracy  \\\n",
       "0  Random-Forest house seats  models/house-rf.pkl        0.965683   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0        0.96087         0.922595        0.928571      0.950176     0.912281   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.936183  0.920354   \n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d. Run Random Forest Classifier sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 100}"
=======
       "{'criterion': 'gini',\n",
       " 'max_depth': 5,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-rf.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.91954</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                    experiment_name                           model_name  \\\n",
       "0  Random-Forest presidential seats  models-currcand/presidential-rf.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.883721              1.0        0.809524   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0     0.944444       1.0  0.871795   \n",
       "\n",
       "                                                                         hyperparameters  \n",
       "0  {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}  "
=======
       "                    experiment_name                  model_name  \\\n",
       "0  Random-Forest presidential seats  models/presidential-rf.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.979769        0.91954         0.973684        0.842105   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0      0.936709          0.8  0.954839  0.820513   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3e. Run Random Forest Classifier sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
<<<<<<< HEAD
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
=======
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random-Forest all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-rf.pkl</td>\n",
       "      <td>0.94615</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>0.922123</td>\n",
       "      <td>0.881288</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.950108</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>0.914405</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.89282</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "           experiment_name                  model_name  train_accuracy  \\\n",
       "0  Random-Forest all seats  models-currcand/all-rf.pkl         0.94615   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.914761         0.922123        0.881288      0.973808     0.950108   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.947261  0.914405   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  "
=======
       "           experiment_name         model_name  train_accuracy  test_accuracy  \\\n",
       "0  Random-Forest all seats  models/all-rf.pkl        0.965072       0.946326   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.923795        0.877301      0.936416     0.908898  0.930063   \n",
       "\n",
       "   test_f1  \\\n",
       "0  0.89282   \n",
       "\n",
       "                                                                      hyperparameters  \n",
       "0  {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_rf(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.919806</td>\n",
       "      <td>0.903981</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.915777</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-tuned-lr.pkl</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.908103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-pca-lr.pkl</td>\n",
       "      <td>0.898219</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
=======
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-pca-lr.pkl</td>\n",
       "      <td>0.898480</td>\n",
       "      <td>0.889429</td>\n",
       "      <td>0.886286</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.919929</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.902794</td>\n",
       "      <td>0.891018</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}</td>\n",
=======
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-pca-lr.pkl</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}</td>\n",
=======
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-pca-lr.pkl</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.866944</td>\n",
       "      <td>0.867446</td>\n",
       "      <td>0.825832</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.868313</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
=======
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-rf.pkl</td>\n",
       "      <td>0.982188</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.952055</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random-Forest house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-rf.pkl</td>\n",
       "      <td>0.951672</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.933069</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>0.975682</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.953900</td>\n",
       "      <td>0.934579</td>\n",
=======
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-rf.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random-Forest all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-rf.pkl</td>\n",
       "      <td>0.946150</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>0.922123</td>\n",
       "      <td>0.881288</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.950108</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>0.914405</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.892820</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                           experiment_name  \\\n",
       "0         Logistic Regression senate seats   \n",
       "1          Logistic Regression house seats   \n",
       "2   Logistic Regression presidential seats   \n",
       "3            Logistic Regression all seats   \n",
       "4                    PCA + LR senate seats   \n",
       "5                     PCA + LR house seats   \n",
       "6              PCA + LR presidential seats   \n",
       "7                       PCA + LR all seats   \n",
       "8               Random-Forest senate seats   \n",
       "9                Random-Forest house seats   \n",
       "10        Random-Forest presidential seats   \n",
       "11                 Random-Forest all seats   \n",
       "\n",
       "                                   model_name  train_accuracy  test_accuracy  \\\n",
       "0         models-currcand/senate-tuned-lr.pkl        0.885496       0.838384   \n",
       "1          models-currcand/house-tuned-lr.pkl        0.906991       0.919806   \n",
       "2   models-currcand/presidential-tuned-lr.pkl        0.947059       0.883721   \n",
       "3            models-currcand/all-tuned-lr.pkl        0.907648       0.883576   \n",
       "4           models-currcand/senate-pca-lr.pkl        0.898219       0.818182   \n",
       "5            models-currcand/house-pca-lr.pkl        0.898480       0.889429   \n",
       "6     models-currcand/presidential-pca-lr.pkl        0.876471       0.906977   \n",
       "7              models-currcand/all-pca-lr.pkl        0.895682       0.866944   \n",
       "8               models-currcand/senate-rf.pkl        0.982188       0.878788   \n",
       "9                models-currcand/house-rf.pkl        0.951672       0.931956   \n",
       "10        models-currcand/presidential-rf.pkl        1.000000       0.883721   \n",
       "11                 models-currcand/all-rf.pkl        0.946150       0.914761   \n",
       "\n",
       "    train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0          0.786585        0.763158      0.928058     0.805556  0.851485   \n",
       "1          0.903981        0.906542      0.915777     0.937198  0.909841   \n",
       "2          0.939024        0.882353      0.950617     0.833333  0.944785   \n",
       "3          0.897646        0.867368      0.918806     0.893709  0.908103   \n",
       "4          0.861314        0.781250      0.848921     0.694444  0.855072   \n",
       "5          0.886286        0.883610      0.919929     0.898551  0.902794   \n",
       "6          0.833333        0.818182      0.925926     1.000000  0.877193   \n",
       "7          0.867446        0.825832      0.932425     0.915401  0.898763   \n",
       "8          0.952055        0.875000      1.000000     0.777778  0.975439   \n",
       "9          0.933069        0.904977      0.975682     0.966184  0.953900   \n",
       "10         1.000000        0.809524      1.000000     0.944444  1.000000   \n",
       "11         0.922123        0.881288      0.973808     0.950108  0.947261   \n",
       "\n",
       "     test_f1  \\\n",
       "0   0.783784   \n",
       "1   0.921615   \n",
       "2   0.857143   \n",
       "3   0.880342   \n",
       "4   0.735294   \n",
       "5   0.891018   \n",
       "6   0.900000   \n",
       "7   0.868313   \n",
       "8   0.823529   \n",
       "9   0.934579   \n",
       "10  0.871795   \n",
       "11  0.914405   \n",
       "\n",
       "                                                                                  hyperparameters  \n",
       "0                                         {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "1                                               {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                                 {'C': 1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                         {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "5     {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}  \n",
       "6    {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}  \n",
       "7    {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8              {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}  \n",
       "9              {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10          {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}  \n",
       "11             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  "
=======
       "                           experiment_name                        model_name  \\\n",
       "0         Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1          Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2   Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3            Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                    PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                     PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6              PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                       PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "8               Random-Forest senate seats              models/senate-rf.pkl   \n",
       "9                Random-Forest house seats               models/house-rf.pkl   \n",
       "10        Random-Forest presidential seats        models/presidential-rf.pkl   \n",
       "11                 Random-Forest all seats                 models/all-rf.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0         0.950658       0.917031         0.854962        0.736842   \n",
       "1         0.947981       0.952795         0.912703        0.940054   \n",
       "2         0.945087       0.896552         0.941176        0.739130   \n",
       "3         0.942526       0.944763         0.880729        0.882845   \n",
       "4         0.947368       0.917031         0.830882        0.736842   \n",
       "5         0.938665       0.945342         0.882216        0.897698   \n",
       "6         0.950867       0.896552         0.930556        0.761905   \n",
       "7         0.934576       0.935383         0.858312        0.853659   \n",
       "8         0.991228       0.925764         0.964286        0.763158   \n",
       "9         0.965683       0.960870         0.922595        0.928571   \n",
       "10        0.979769       0.919540         0.973684        0.842105   \n",
       "11        0.965072       0.946326         0.923795        0.877301   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "0       0.811594     0.756757  0.832714  0.746667   \n",
       "1       0.888628     0.864662  0.900505  0.900783   \n",
       "2       0.810127     0.850000  0.870748  0.790698   \n",
       "3       0.888597     0.894068  0.884646  0.888421   \n",
       "4       0.818841     0.756757  0.824818  0.746667   \n",
       "5       0.886870     0.879699  0.884537  0.888608   \n",
       "6       0.848101     0.800000  0.887417  0.780488   \n",
       "7       0.881766     0.889831  0.869881  0.871369   \n",
       "8       0.978261     0.783784  0.971223  0.773333   \n",
       "9       0.950176     0.912281  0.936183  0.920354   \n",
       "10      0.936709     0.800000  0.954839  0.820513   \n",
       "11      0.936416     0.908898  0.930063  0.892820   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                             {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5    {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6   {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7   {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "9             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10            {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "11            {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models-currcand/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Algorithm 4: Ensemble Gradient Boosting Classifier\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient boosting classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#grid search for gradient boosting classifier\n",
    "def grid_search_gbc(x_train, y_train):\n",
    "    ''' Function to grid search for Gradient Boosting Classifier '''\n",
    "    #create param grid\n",
    "    param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['friedman_mse', 'mse', 'mae']\n",
    "    }\n",
    "    #create grid search\n",
    "    grid_search = GridSearchCV(GradientBoostingClassifier(), param_grid, cv=5, return_train_score=True, verbose=1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    #display best params\n",
    "    display(best_params)\n",
    "    return grid_search, best_params\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_gbc(x_train, y_train, grid_search):\n",
    "    ''' Function to fit using best params '''\n",
    "    #get best estimator\n",
    "    best_estimator = grid_search.best_estimator_\n",
    "    #fit best estimator\n",
    "    best_estimator.fit(x_train, y_train)\n",
    "    #get best params\n",
    "    best_params = grid_search.best_params_\n",
    "    return best_estimator, best_params\n",
    "\n",
    "#run sequence gradient boosting classifier\n",
    "def run_sequence_gbc(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Gradient Boosting Classifier '''\n",
    "\n",
    "    grid_search, best_params = grid_search_gbc(x_train, y_train)\n",
    "   \n",
    "    best_estimator, best_params = fit_using_best_params_gbc(x_train, y_train, grid_search)\n",
    "  \n",
    "    y_train_pred = best_estimator.predict(x_train)    \n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_precision = precision_score(y_train, y_train_pred)   \n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "\n",
    "    train_recall = recall_score(y_train, y_train_pred)    \n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "   \n",
    "    train_f1 = f1_score(y_train, y_train_pred) \n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary with train and test accuracy, precision, recall and f1\n",
    "    metrics = {\n",
    "    'experiment_name': f'Gradient-Boosting {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models-currcand/{set_name}-gbc.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models-currcand/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b. Run Ensemble Gradient Boosting Classifier sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
<<<<<<< HEAD
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
=======
       " 'max_depth': 6,\n",
       " 'max_features': 'log2',\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/senate-gbc.pkl</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                  experiment_name                      model_name  \\\n",
       "0  Gradient-Boosting senate seats  models-currcand/senate-gbc.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.909091              1.0        0.864865   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0     0.888889       1.0  0.876712   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}  "
=======
       "                  experiment_name             model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting senate seats  models/senate-gbc.pkl        0.997807   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.934498         0.992754        0.789474      0.992754     0.810811   \n",
       "\n",
       "   train_f1  test_f1  \\\n",
       "0  0.992754      0.8   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c. Run Ensemble Gradient Boosting Classifier sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
<<<<<<< HEAD
       " 'max_depth': 8,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models-currcand/house-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.933649</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_name                     model_name  \\\n",
       "0  Gradient-Boosting house seats  models-currcand/house-gbc.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.941677              1.0        0.933649   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0     0.951691       1.0  0.942584   \n",
       "\n",
       "                                                                              hyperparameters  \n",
       "0  {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d. Run Ensemble Gradient Boosting Classifier sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models-currcand/presidential-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        experiment_name                            model_name  \\\n",
       "0  Gradient-Boosting presidential seats  models-currcand/presidential-gbc.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.883721              1.0        0.882353   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0     0.833333       1.0  0.857143   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e. Run Ensemble Gradient Boosting Classifier sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'max_depth': 8,\n",
=======
       " 'max_depth': 6,\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models-currcand/all-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
=======
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models/house-gbc.pkl</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.961491</td>\n",
       "      <td>0.996487</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "               experiment_name                   model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting all seats  models-currcand/all-gbc.pkl             1.0   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.928274              1.0        0.910042           1.0     0.943601   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0       1.0  0.926518   \n",
       "\n",
       "                                                                              hyperparameters  \n",
       "0  {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}  "
=======
       "                 experiment_name            model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting house seats  models/house-gbc.pkl        0.998447   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.961491         0.996487          0.9202      0.997655     0.924812   \n",
       "\n",
       "   train_f1  test_f1  \\\n",
       "0  0.997071   0.9225   \n",
       "\n",
       "                                                                              hyperparameters  \n",
       "0  {'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d. Run Ensemble Gradient Boosting Classifier sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 7,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        experiment_name                   model_name  \\\n",
       "0  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.942529              1.0        0.857143   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0          0.9       1.0  0.878049   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4e. Run Ensemble Gradient Boosting Classifier sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'auto',\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.99987</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               experiment_name          model_name  train_accuracy  \\\n",
       "0  Gradient-Boosting all seats  models/all-gbc.pkl         0.99987   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.952579              1.0        0.884848      0.999475     0.927966   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.999737  0.905895   \n",
       "\n",
       "                                                                     hyperparameters  \n",
       "0  {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics_df = run_sequence_gbc(x_train, y_train, x_val, y_val, set_name = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 39,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-tuned-lr.pkl</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0.838384</td>\n",
       "      <td>0.786585</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.928058</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.851485</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/senate-tuned-lr.pkl</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.832714</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-tuned-lr.pkl</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.919806</td>\n",
       "      <td>0.903981</td>\n",
       "      <td>0.906542</td>\n",
       "      <td>0.915777</td>\n",
       "      <td>0.937198</td>\n",
       "      <td>0.909841</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/house-tuned-lr.pkl</td>\n",
       "      <td>0.947981</td>\n",
       "      <td>0.952795</td>\n",
       "      <td>0.912703</td>\n",
       "      <td>0.940054</td>\n",
       "      <td>0.888628</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>0.900505</td>\n",
       "      <td>0.900783</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.947059</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.944785</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/presidential-tuned-lr.pkl</td>\n",
       "      <td>0.945087</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.870748</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-tuned-lr.pkl</td>\n",
       "      <td>0.907648</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.897646</td>\n",
       "      <td>0.867368</td>\n",
       "      <td>0.918806</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.908103</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}</td>\n",
=======
       "      <td>models/all-tuned-lr.pkl</td>\n",
       "      <td>0.942526</td>\n",
       "      <td>0.944763</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.882845</td>\n",
       "      <td>0.888597</td>\n",
       "      <td>0.894068</td>\n",
       "      <td>0.884646</td>\n",
       "      <td>0.888421</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'penalty': 'l1'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCA + LR senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-pca-lr.pkl</td>\n",
       "      <td>0.898219</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.861314</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
=======
       "      <td>models/senate-pca-lr.pkl</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.830882</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.824818</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>{'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PCA + LR house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-pca-lr.pkl</td>\n",
       "      <td>0.898480</td>\n",
       "      <td>0.889429</td>\n",
       "      <td>0.886286</td>\n",
       "      <td>0.883610</td>\n",
       "      <td>0.919929</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.902794</td>\n",
       "      <td>0.891018</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}</td>\n",
=======
       "      <td>models/house-pca-lr.pkl</td>\n",
       "      <td>0.938665</td>\n",
       "      <td>0.945342</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.897698</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.879699</td>\n",
       "      <td>0.884537</td>\n",
       "      <td>0.888608</td>\n",
       "      <td>{'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-pca-lr.pkl</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}</td>\n",
=======
       "      <td>models/presidential-pca-lr.pkl</td>\n",
       "      <td>0.950867</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.930556</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.887417</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>{'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PCA + LR all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-pca-lr.pkl</td>\n",
       "      <td>0.895682</td>\n",
       "      <td>0.866944</td>\n",
       "      <td>0.867446</td>\n",
       "      <td>0.825832</td>\n",
       "      <td>0.932425</td>\n",
       "      <td>0.915401</td>\n",
       "      <td>0.898763</td>\n",
       "      <td>0.868313</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
=======
       "      <td>models/all-pca-lr.pkl</td>\n",
       "      <td>0.934576</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>0.858312</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.881766</td>\n",
       "      <td>0.889831</td>\n",
       "      <td>0.869881</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>{'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random-Forest senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-rf.pkl</td>\n",
       "      <td>0.982188</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.952055</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.975439</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/senate-rf.pkl</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.925764</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random-Forest house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-rf.pkl</td>\n",
       "      <td>0.951672</td>\n",
       "      <td>0.931956</td>\n",
       "      <td>0.933069</td>\n",
       "      <td>0.904977</td>\n",
       "      <td>0.975682</td>\n",
       "      <td>0.966184</td>\n",
       "      <td>0.953900</td>\n",
       "      <td>0.934579</td>\n",
=======
       "      <td>models/house-rf.pkl</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>0.960870</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.950176</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.920354</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random-Forest presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-rf.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/presidential-rf.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random-Forest all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-rf.pkl</td>\n",
       "      <td>0.946150</td>\n",
       "      <td>0.914761</td>\n",
       "      <td>0.922123</td>\n",
       "      <td>0.881288</td>\n",
       "      <td>0.973808</td>\n",
       "      <td>0.950108</td>\n",
       "      <td>0.947261</td>\n",
       "      <td>0.914405</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/all-rf.pkl</td>\n",
       "      <td>0.965072</td>\n",
       "      <td>0.946326</td>\n",
       "      <td>0.923795</td>\n",
       "      <td>0.877301</td>\n",
       "      <td>0.936416</td>\n",
       "      <td>0.908898</td>\n",
       "      <td>0.930063</td>\n",
       "      <td>0.892820</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/senate-gbc.pkl</td>\n",
       "      <td>0.997807</td>\n",
       "      <td>0.934498</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.992754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/house-gbc.pkl</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.961491</td>\n",
       "      <td>0.996487</td>\n",
       "      <td>0.920200</td>\n",
       "      <td>0.997655</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.997071</td>\n",
       "      <td>0.922500</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
=======
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
=======
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                           experiment_name  \\\n",
       "0         Logistic Regression senate seats   \n",
       "1          Logistic Regression house seats   \n",
       "2   Logistic Regression presidential seats   \n",
       "3            Logistic Regression all seats   \n",
       "4                    PCA + LR senate seats   \n",
       "5                     PCA + LR house seats   \n",
       "6              PCA + LR presidential seats   \n",
       "7                       PCA + LR all seats   \n",
       "8               Random-Forest senate seats   \n",
       "9                Random-Forest house seats   \n",
       "10        Random-Forest presidential seats   \n",
       "11                 Random-Forest all seats   \n",
       "12          Gradient-Boosting senate seats   \n",
       "13           Gradient-Boosting house seats   \n",
       "14    Gradient-Boosting presidential seats   \n",
       "15             Gradient-Boosting all seats   \n",
       "\n",
       "                                   model_name  train_accuracy  test_accuracy  \\\n",
       "0         models-currcand/senate-tuned-lr.pkl        0.885496       0.838384   \n",
       "1          models-currcand/house-tuned-lr.pkl        0.906991       0.919806   \n",
       "2   models-currcand/presidential-tuned-lr.pkl        0.947059       0.883721   \n",
       "3            models-currcand/all-tuned-lr.pkl        0.907648       0.883576   \n",
       "4           models-currcand/senate-pca-lr.pkl        0.898219       0.818182   \n",
       "5            models-currcand/house-pca-lr.pkl        0.898480       0.889429   \n",
       "6     models-currcand/presidential-pca-lr.pkl        0.876471       0.906977   \n",
       "7              models-currcand/all-pca-lr.pkl        0.895682       0.866944   \n",
       "8               models-currcand/senate-rf.pkl        0.982188       0.878788   \n",
       "9                models-currcand/house-rf.pkl        0.951672       0.931956   \n",
       "10        models-currcand/presidential-rf.pkl        1.000000       0.883721   \n",
       "11                 models-currcand/all-rf.pkl        0.946150       0.914761   \n",
       "12             models-currcand/senate-gbc.pkl        1.000000       0.909091   \n",
       "13              models-currcand/house-gbc.pkl        1.000000       0.941677   \n",
       "14       models-currcand/presidential-gbc.pkl        1.000000       0.883721   \n",
       "15                models-currcand/all-gbc.pkl        1.000000       0.928274   \n",
       "\n",
       "    train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0          0.786585        0.763158      0.928058     0.805556  0.851485   \n",
       "1          0.903981        0.906542      0.915777     0.937198  0.909841   \n",
       "2          0.939024        0.882353      0.950617     0.833333  0.944785   \n",
       "3          0.897646        0.867368      0.918806     0.893709  0.908103   \n",
       "4          0.861314        0.781250      0.848921     0.694444  0.855072   \n",
       "5          0.886286        0.883610      0.919929     0.898551  0.902794   \n",
       "6          0.833333        0.818182      0.925926     1.000000  0.877193   \n",
       "7          0.867446        0.825832      0.932425     0.915401  0.898763   \n",
       "8          0.952055        0.875000      1.000000     0.777778  0.975439   \n",
       "9          0.933069        0.904977      0.975682     0.966184  0.953900   \n",
       "10         1.000000        0.809524      1.000000     0.944444  1.000000   \n",
       "11         0.922123        0.881288      0.973808     0.950108  0.947261   \n",
       "12         1.000000        0.864865      1.000000     0.888889  1.000000   \n",
       "13         1.000000        0.933649      1.000000     0.951691  1.000000   \n",
       "14         1.000000        0.882353      1.000000     0.833333  1.000000   \n",
       "15         1.000000        0.910042      1.000000     0.943601  1.000000   \n",
       "\n",
       "     test_f1  \\\n",
       "0   0.783784   \n",
       "1   0.921615   \n",
       "2   0.857143   \n",
       "3   0.880342   \n",
       "4   0.735294   \n",
       "5   0.891018   \n",
       "6   0.900000   \n",
       "7   0.868313   \n",
       "8   0.823529   \n",
       "9   0.934579   \n",
       "10  0.871795   \n",
       "11  0.914405   \n",
       "12  0.876712   \n",
       "13  0.942584   \n",
       "14  0.857143   \n",
       "15  0.926518   \n",
       "\n",
       "                                                                                  hyperparameters  \n",
       "0                                         {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "1                                               {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                                 {'C': 1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                         {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "5     {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 9}  \n",
       "6    {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}  \n",
       "7    {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8              {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}  \n",
       "9              {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10          {'criterion': 'entropy', 'max_depth': 8, 'max_features': 'log2', 'n_estimators': 100}  \n",
       "11             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "12              {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "13     {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}  \n",
       "14              {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 100}  \n",
       "15     {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 200}  "
=======
       "                           experiment_name                        model_name  \\\n",
       "0         Logistic Regression senate seats        models/senate-tuned-lr.pkl   \n",
       "1          Logistic Regression house seats         models/house-tuned-lr.pkl   \n",
       "2   Logistic Regression presidential seats  models/presidential-tuned-lr.pkl   \n",
       "3            Logistic Regression all seats           models/all-tuned-lr.pkl   \n",
       "4                    PCA + LR senate seats          models/senate-pca-lr.pkl   \n",
       "5                     PCA + LR house seats           models/house-pca-lr.pkl   \n",
       "6              PCA + LR presidential seats    models/presidential-pca-lr.pkl   \n",
       "7                       PCA + LR all seats             models/all-pca-lr.pkl   \n",
       "8               Random-Forest senate seats              models/senate-rf.pkl   \n",
       "9                Random-Forest house seats               models/house-rf.pkl   \n",
       "10        Random-Forest presidential seats        models/presidential-rf.pkl   \n",
       "11                 Random-Forest all seats                 models/all-rf.pkl   \n",
       "12          Gradient-Boosting senate seats             models/senate-gbc.pkl   \n",
       "13           Gradient-Boosting house seats              models/house-gbc.pkl   \n",
       "14    Gradient-Boosting presidential seats       models/presidential-gbc.pkl   \n",
       "15             Gradient-Boosting all seats                models/all-gbc.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0         0.950658       0.917031         0.854962        0.736842   \n",
       "1         0.947981       0.952795         0.912703        0.940054   \n",
       "2         0.945087       0.896552         0.941176        0.739130   \n",
       "3         0.942526       0.944763         0.880729        0.882845   \n",
       "4         0.947368       0.917031         0.830882        0.736842   \n",
       "5         0.938665       0.945342         0.882216        0.897698   \n",
       "6         0.950867       0.896552         0.930556        0.761905   \n",
       "7         0.934576       0.935383         0.858312        0.853659   \n",
       "8         0.991228       0.925764         0.964286        0.763158   \n",
       "9         0.965683       0.960870         0.922595        0.928571   \n",
       "10        0.979769       0.919540         0.973684        0.842105   \n",
       "11        0.965072       0.946326         0.923795        0.877301   \n",
       "12        0.997807       0.934498         0.992754        0.789474   \n",
       "13        0.998447       0.961491         0.996487        0.920200   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "0       0.811594     0.756757  0.832714  0.746667   \n",
       "1       0.888628     0.864662  0.900505  0.900783   \n",
       "2       0.810127     0.850000  0.870748  0.790698   \n",
       "3       0.888597     0.894068  0.884646  0.888421   \n",
       "4       0.818841     0.756757  0.824818  0.746667   \n",
       "5       0.886870     0.879699  0.884537  0.888608   \n",
       "6       0.848101     0.800000  0.887417  0.780488   \n",
       "7       0.881766     0.889831  0.869881  0.871369   \n",
       "8       0.978261     0.783784  0.971223  0.773333   \n",
       "9       0.950176     0.912281  0.936183  0.920354   \n",
       "10      0.936709     0.800000  0.954839  0.820513   \n",
       "11      0.936416     0.908898  0.930063  0.892820   \n",
       "12      0.992754     0.810811  0.992754  0.800000   \n",
       "13      0.997655     0.924812  0.997071  0.922500   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "\n",
       "                                                                                 hyperparameters  \n",
       "0                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "1                                             {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}  \n",
       "2                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "3                                              {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}  \n",
       "4   {'logisticregression__C': 100, 'logisticregression__penalty': 'l2', 'pca__n_components': 10}  \n",
       "5    {'logisticregression__C': 10, 'logisticregression__penalty': 'l2', 'pca__n_components': 60}  \n",
       "6   {'logisticregression__C': 0.1, 'logisticregression__penalty': 'l2', 'pca__n_components': 30}  \n",
       "7   {'logisticregression__C': 1000, 'logisticregression__penalty': 'l2', 'pca__n_components': 5}  \n",
       "8             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'sqrt', 'n_estimators': 100}  \n",
       "9             {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "10            {'criterion': 'gini', 'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "11            {'criterion': 'gini', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 200}  \n",
       "12             {'criterion': 'mse', 'max_depth': 6, 'max_features': 'log2', 'n_estimators': 100}  \n",
       "13    {'criterion': 'friedman_mse', 'max_depth': 6, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "14             {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}  \n",
       "15             {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pd.read_csv('models-currcand/metrics.csv')\n",
    "display(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Algorithm 5: Stacking Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5a. Helper Functions for this task**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacking Classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "#grid search for stacking classifier\n",
    "def grid_search_stacking(x_train, y_train, set=None):\n",
    "    ''' Function to grid search for Stacking Classifier '''\n",
    "    #load models from pkl files senate\n",
    "    model1 = pickle.load(open(f'models-currcand/{set}-rf.pkl', 'rb'))\n",
    "    model2 = pickle.load(open(f'models-currcand/{set}-gbc.pkl', 'rb'))\n",
    "    model3 = pickle.load(open(f'models-currcand/{set}-tuned-lr.pkl', 'rb'))\n",
    "    model4 = pickle.load(open(f'models-currcand/{set}-pca-lr.pkl', 'rb'))\n",
    "    #create a list of models\n",
    "    models = [('rf', model1), ('gbc', model2), ('lr', model3), ('pca-lr', model4)]\n",
    "    #create a stacking classifier\n",
    "    stacking = StackingClassifier(estimators=models, final_estimator=LogisticRegression())\n",
    "    #create a dictionary of params\n",
    "    params = {\n",
    "    'final_estimator__C': [0.1, 1, 10, 100, 1000],\n",
    "    'final_estimator__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'final_estimator__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],    \n",
    "    }\n",
    "    #create a grid search\n",
    "    grid_search = GridSearchCV(stacking, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "    #fit grid search\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    #return grid search and best params\n",
    "    return grid_search, grid_search.best_params_\n",
    "\n",
    "#fit using best params\n",
    "def fit_using_best_params_stacking(x_train, y_train, grid_search, set=None):\n",
    "    ''' Function to fit using best params for Stacking Classifier '''\n",
    "    #load models from pkl files\n",
    "    model1 = pickle.load(open(f'models-currcand/{set}-rf.pkl', 'rb'))\n",
    "    model2 = pickle.load(open(f'models-currcand/{set}-gbc.pkl', 'rb'))\n",
    "    model3 = pickle.load(open(f'models-currcand/{set}-tuned-lr.pkl', 'rb'))\n",
    "    model4 = pickle.load(open(f'models-currcand/{set}-pca-lr.pkl', 'rb'))\n",
    "    #create a list of models\n",
    "    models = [('rf', model1), ('gbc', model2), ('lr', model3), ('pca-lr', model4)]\n",
    "    #create a stacking classifier\n",
    "    stacking = StackingClassifier(estimators=models, final_estimator=LogisticRegression())\n",
    "    #fit stacking classifier\n",
    "    stacking.fit(x_train, y_train)\n",
    "    #return best estimator and best params\n",
    "    return stacking, grid_search.best_params_\n",
    "\n",
    "#run sequence for stacking classifier\n",
    "def run_sequence_stacking(x_train, y_train, x_val, y_val, set_name=None):\n",
    "    ''' Function to run sequence for Stacking Classifier '''\n",
    "    #grid search\n",
    "    grid_search, best_params = grid_search_stacking(x_train, y_train, set=set_name)\n",
    "    #fit using best params\n",
    "    best_estimator, best_params = fit_using_best_params_stacking(x_train, y_train, grid_search, set=set_name)\n",
    "    #predict on train and test\n",
    "    y_train_pred = best_estimator.predict(x_train)\n",
    "    y_val_pred = best_estimator.predict(x_val)\n",
    "    #get metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    test_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    test_precision = precision_score(y_val, y_val_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    test_recall = recall_score(y_val, y_val_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred)\n",
    "    test_f1 = f1_score(y_val, y_val_pred)\n",
    "    #create a dictionary of metrics\n",
    "    metrics = {\n",
    "    'experiment_name': f'Stacking {set_name} seats', \n",
    "    'train_accuracy': train_accuracy, \n",
    "    'test_accuracy': test_accuracy, \n",
    "    'train_precision': train_precision, \n",
    "    'test_precision': test_precision, \n",
    "    'train_recall': train_recall, \n",
    "    'test_recall': test_recall, \n",
    "    'train_f1': train_f1, \n",
    "    'test_f1': test_f1,\n",
    "    'hyperparameters': [best_params]}\n",
    "    #create a dataframe with metrics\n",
    "    metrics_df = pd.DataFrame(metrics)   \n",
    "    #create model name\n",
    "    model_name = f'models-currcand/{set_name}-stacking.pkl'\n",
    "    metrics_df.insert(1, 'model_name', model_name)\n",
    "    #save model\n",
    "    pickle.dump(best_estimator, open(model_name, 'wb'))\n",
    "    #append metrics_df to metrics.csv\n",
    "    display(metrics_df)\n",
    "    metrics_df.to_csv('models-currcand/metrics.csv', mode='a', header=False, index=False)\n",
    "    return model, metrics_df\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5b. Run Stacking Algorithm sequence on senate seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 41,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking senate seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/senate-stacking.pkl</td>\n",
       "      <td>0.979644</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}</td>\n",
=======
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "         experiment_name                           model_name  train_accuracy  \\\n",
       "0  Stacking senate seats  models-currcand/senate-stacking.pkl        0.979644   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.878788         0.971223           0.875      0.971223     0.777778   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.971223  0.823529   \n",
       "\n",
       "                                                                                     hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}  "
=======
       "         experiment_name                  model_name  train_accuracy  \\\n",
       "0  Stacking senate seats  models/senate-stacking.pkl        0.973684   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.938865         0.931818        0.828571      0.891304     0.783784   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.911111  0.805556   \n",
       "\n",
       "                                                                                    hyperparameters  \n",
       "0  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_senate)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='senate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5c. Run Stacking Algorithm sequence on house seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 42,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking house seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/house-stacking.pkl</td>\n",
       "      <td>0.983891</td>\n",
       "      <td>0.935601</td>\n",
       "      <td>0.980577</td>\n",
       "      <td>0.932854</td>\n",
       "      <td>0.988138</td>\n",
       "      <td>0.939614</td>\n",
       "      <td>0.984343</td>\n",
       "      <td>0.936221</td>\n",
       "      <td>{'final_estimator__C': 1000, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'sag'}</td>\n",
=======
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "        experiment_name                          model_name  train_accuracy  \\\n",
       "0  Stacking house seats  models-currcand/house-stacking.pkl        0.983891   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.935601         0.980577        0.932854      0.988138     0.939614   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.984343  0.936221   \n",
       "\n",
       "                                                                                    hyperparameters  \n",
       "0  {'final_estimator__C': 1000, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'sag'}  "
=======
       "        experiment_name                 model_name  train_accuracy  \\\n",
       "0  Stacking house seats  models/house-stacking.pkl        0.980745   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.963354         0.965842        0.938144      0.961313     0.912281   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.963572  0.925032   \n",
       "\n",
       "                                                                                  hyperparameters  \n",
       "0  {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_house)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5d. Run Stacking Algorithm sequence on presidential seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking presidential seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/presidential-stacking.pkl</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
=======
       "      <td>models/presidential-stacking.pkl</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.986486</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.924051</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.954248</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'lbfgs'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "               experiment_name                                 model_name  \\\n",
       "0  Stacking presidential seats  models-currcand/presidential-stacking.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0             1.0       0.906977              1.0        0.888889   \n",
       "\n",
       "   train_recall  test_recall  train_f1   test_f1  \\\n",
       "0           1.0     0.888889       1.0  0.888889   \n",
       "\n",
       "                                                                                     hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}  "
=======
       "               experiment_name                        model_name  \\\n",
       "0  Stacking presidential seats  models/presidential-stacking.pkl   \n",
       "\n",
       "   train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "0        0.979769       0.931034         0.986486            0.85   \n",
       "\n",
       "   train_recall  test_recall  train_f1  test_f1  \\\n",
       "0      0.924051         0.85  0.954248     0.85   \n",
       "\n",
       "                                                                                       hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'lbfgs'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df_presidential)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='presidential')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5e. Run Stacking Algorithm sequence on all seats**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 44,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stacking all seats</td>\n",
<<<<<<< HEAD
       "      <td>models-currcand/all-stacking.pkl</td>\n",
       "      <td>0.986993</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.991095</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}</td>\n",
=======
       "      <td>models/all-stacking.pkl</td>\n",
       "      <td>0.985794</td>\n",
       "      <td>0.952058</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.889344</td>\n",
       "      <td>0.972675</td>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.971399</td>\n",
       "      <td>0.904167</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "      experiment_name                        model_name  train_accuracy  \\\n",
       "0  Stacking all seats  models-currcand/all-stacking.pkl        0.986993   \n",
       "\n",
       "   test_accuracy  train_precision  test_precision  train_recall  test_recall  \\\n",
       "0       0.928274         0.982857        0.910042      0.991095     0.943601   \n",
       "\n",
       "   train_f1   test_f1  \\\n",
       "0  0.986959  0.926518   \n",
       "\n",
       "                                                                                         hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}  "
=======
       "      experiment_name               model_name  train_accuracy  test_accuracy  \\\n",
       "0  Stacking all seats  models/all-stacking.pkl        0.985794       0.952058   \n",
       "\n",
       "   train_precision  test_precision  train_recall  test_recall  train_f1  \\\n",
       "0         0.970126        0.889344      0.972675     0.919492  0.971399   \n",
       "\n",
       "    test_f1  \\\n",
       "0  0.904167   \n",
       "\n",
       "                                                                                     hyperparameters  \n",
       "0  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'none', 'final_estimator__solver': 'sag'}  "
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = pre_process(df)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=69)\n",
    "model, metrics = run_sequence_stacking(x_train, y_train, x_val, y_val, set_name='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5f. Summary of results**"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 45,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv('models-currcand/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 46,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['segment'] = metrics['experiment_name'].apply(lambda x: 'senate' if 'senate' in x else 'house' if 'house' in x else 'presidential' if 'presidential' in x else 'all')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 47,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>13</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models-currcand/house-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stacking all seats</td>\n",
       "      <td>models-currcand/all-stacking.pkl</td>\n",
       "      <td>0.986993</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.991095</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
       "      <td>models-currcand/senate-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
       "      <td>senate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Stacking presidential seats</td>\n",
       "      <td>models-currcand/presidential-stacking.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "      <td>presidential</td>\n",
=======
       "      <th>17</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "      <td>presidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
       "      <td>senate</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                   experiment_name                                 model_name  \\\n",
       "13   Gradient-Boosting house seats              models-currcand/house-gbc.pkl   \n",
       "19              Stacking all seats           models-currcand/all-stacking.pkl   \n",
       "12  Gradient-Boosting senate seats             models-currcand/senate-gbc.pkl   \n",
       "18     Stacking presidential seats  models-currcand/presidential-stacking.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "13        1.000000       0.941677         1.000000        0.933649   \n",
       "19        0.986993       0.928274         0.982857        0.910042   \n",
       "12        1.000000       0.909091         1.000000        0.864865   \n",
       "18        1.000000       0.906977         1.000000        0.888889   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "13      1.000000     0.951691  1.000000  0.942584   \n",
       "19      0.991095     0.943601  0.986959  0.926518   \n",
       "12      1.000000     0.888889  1.000000  0.876712   \n",
       "18      1.000000     0.888889  1.000000  0.888889   \n",
       "\n",
       "                                                                                          hyperparameters  \\\n",
       "13             {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}   \n",
       "19  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}   \n",
       "12                      {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}   \n",
       "18      {'final_estimator__C': 0.1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}   \n",
       "\n",
       "         segment  \n",
       "13         house  \n",
       "19           all  \n",
       "12        senate  \n",
       "18  presidential  "
      ]
     },
     "execution_count": 47,
=======
       "                         experiment_name                   model_name  \\\n",
       "17                  Stacking house seats    models/house-stacking.pkl   \n",
       "15           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "14  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "16                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "17        0.980745       0.963354         0.965842        0.938144   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "16        0.973684       0.938865         0.931818        0.828571   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "17      0.961313     0.912281  0.963572  0.925032   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "16      0.891304     0.783784  0.911111  0.805556   \n",
       "\n",
       "                                                                                     hyperparameters  \\\n",
       "17    {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}   \n",
       "15                 {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}   \n",
       "14                 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}   \n",
       "16  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}   \n",
       "\n",
       "         segment  \n",
       "17         house  \n",
       "15           all  \n",
       "14  presidential  \n",
       "16        senate  "
      ]
     },
     "execution_count": 130,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest performing model in each segment based on test accuracy\n",
    "metrics.sort_values(by='test_accuracy', ascending=False).groupby('segment').head(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
<<<<<<< HEAD
       "      <th>13</th>\n",
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models-currcand/house-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>{'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Stacking all seats</td>\n",
       "      <td>models-currcand/all-stacking.pkl</td>\n",
       "      <td>0.986993</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.991095</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>{'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PCA + LR presidential seats</td>\n",
       "      <td>models-currcand/presidential-pca-lr.pkl</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>{'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}</td>\n",
       "      <td>presidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
       "      <td>models-currcand/senate-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}</td>\n",
=======
       "      <th>17</th>\n",
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.961313</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>{'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}</td>\n",
       "      <td>house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.999475</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}</td>\n",
       "      <td>presidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>{'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "      <td>senate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                   experiment_name                               model_name  \\\n",
       "13   Gradient-Boosting house seats            models-currcand/house-gbc.pkl   \n",
       "19              Stacking all seats         models-currcand/all-stacking.pkl   \n",
       "6      PCA + LR presidential seats  models-currcand/presidential-pca-lr.pkl   \n",
       "12  Gradient-Boosting senate seats           models-currcand/senate-gbc.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "13        1.000000       0.941677         1.000000        0.933649   \n",
       "19        0.986993       0.928274         0.982857        0.910042   \n",
       "6         0.876471       0.906977         0.833333        0.818182   \n",
       "12        1.000000       0.909091         1.000000        0.864865   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "13      1.000000     0.951691  1.000000  0.942584   \n",
       "19      0.991095     0.943601  0.986959  0.926518   \n",
       "6       0.925926     1.000000  0.877193  0.900000   \n",
       "12      1.000000     0.888889  1.000000  0.876712   \n",
       "\n",
       "                                                                                          hyperparameters  \\\n",
       "13             {'criterion': 'friedman_mse', 'max_depth': 8, 'max_features': 'auto', 'n_estimators': 100}   \n",
       "19  {'final_estimator__C': 0.1, 'final_estimator__penalty': 'l1', 'final_estimator__solver': 'liblinear'}   \n",
       "6            {'logisticregression__C': 0.01, 'logisticregression__penalty': 'l2', 'pca__n_components': 6}   \n",
       "12                      {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 100}   \n",
       "\n",
       "         segment  \n",
       "13         house  \n",
       "19           all  \n",
       "6   presidential  \n",
       "12        senate  "
      ]
     },
     "execution_count": 48,
=======
       "                         experiment_name                   model_name  \\\n",
       "17                  Stacking house seats    models/house-stacking.pkl   \n",
       "15           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "14  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "16                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "    train_accuracy  test_accuracy  train_precision  test_precision  \\\n",
       "17        0.980745       0.963354         0.965842        0.938144   \n",
       "15        0.999870       0.952579         1.000000        0.884848   \n",
       "14        1.000000       0.942529         1.000000        0.857143   \n",
       "16        0.973684       0.938865         0.931818        0.828571   \n",
       "\n",
       "    train_recall  test_recall  train_f1   test_f1  \\\n",
       "17      0.961313     0.912281  0.963572  0.925032   \n",
       "15      0.999475     0.927966  0.999737  0.905895   \n",
       "14      1.000000     0.900000  1.000000  0.878049   \n",
       "16      0.891304     0.783784  0.911111  0.805556   \n",
       "\n",
       "                                                                                     hyperparameters  \\\n",
       "17    {'final_estimator__C': 1, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'saga'}   \n",
       "15                 {'criterion': 'mse', 'max_depth': 6, 'max_features': 'auto', 'n_estimators': 200}   \n",
       "14                 {'criterion': 'mse', 'max_depth': 7, 'max_features': 'sqrt', 'n_estimators': 200}   \n",
       "16  {'final_estimator__C': 10, 'final_estimator__penalty': 'l2', 'final_estimator__solver': 'lbfgs'}   \n",
       "\n",
       "         segment  \n",
       "17         house  \n",
       "15           all  \n",
       "14  presidential  \n",
       "16        senate  "
      ]
     },
     "execution_count": 131,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#highest performing model in each segment based on f1y\n",
    "metrics.sort_values(by='test_f1', ascending=False).groupby('segment').head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation to baseline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAJcCAYAAABHfaGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABDbUlEQVR4nO3dfbhdd13n/feHtJTyUGmnpzUkgVSNQNqRQo+xisOgVRsQSfWmTLgHGrUzYbAozMWoLTO3oE603oMoKO1M5KGpVGqGBxsZCtRoZRhr6ykU2jT0bqS1OTQkoVBpUYMJ3/uP/YtuknPSk+Scvc8+6/26rn3ttb/rYX83V+zPz1lr/VaqCkmSJElSNzxu2A1IkiRJkgbHEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoDRkSb4/yV8k+dskX07yf5J89xx/5/1Jfmguv0OSpNkw1ZiV5CeTfHJYPUmj7oRhNyB1WZJTgA8DrwE2A48H/hWwb5h9SZIkaeHyTKA0XN8JUFXvq6oDVfX3VfXxqvosQJKfTrI9yVeSfCzJMw7umKSS/Ick97b170iStu7bk/xpkoeSfCnJdUme2tb9PvB04I+TPJrkF1r9/HZG8uEkn0nywoH+LyFJ0jFI8uwkN7fxa1uSl/atuznJv+v7/E9nENPzW0n2tKtxPpvknLbupCRvSfJAkt1J/nuSkwf/66S5YQiUhuv/Aw4k2ZTkRUlOPbgiyUXAG4GfAMaA/w2875D9XwJ8N/Ac4OXAhQd3B34deBrwbGAZ8GaAqnoV8ADwY1X15Kr6f5MsAf4X8F+B04D/BHwgydhs/2BJkmZLkhOBPwY+DpwB/CxwXZJnzmD3HwFeQO8Psk8F/g3wUFv3G61+LvAdwBLgl2axdWmoDIHSEFXVV4HvBwr4PWBvki1JzgReDfx6VW2vqv3ArwHn9p8NBK6sqoer6gHgz+gNVlTVjqq6qar2VdVe4K3Avz5CK68EPlJVH6mqb1TVTcAE8OLZ/cWSJB2TP2pn+h5O8jBwVaufDzyZ3nj49ar6U3q3WbxiBsf8R+ApwLOAtPF2V7uq5t8D/7GqvlxVj9Abg9fO8m+ShsYQKA1ZG3R+sqqWAufQO3v328AzgLf1DXhfpneGb0nf7l/sW/47egMhSc5Icn2SLyT5KvBe4PQjtPEM4OJDBtjvBxbPxm+UJOk4XVRVTz34An6m1Z8G7Kyqb/Rt+zd881g5pRYYfxd4B7A7ycZ2r/4Y8ETg9r4x8aOtLi0IhkBpHqmqzwHX0AuDO4FX9w96VXVyVf3FDA716/TOLn5XVZ1C70xf+r/qkO13Ar9/yHc9qaquPO4fJUnS3HkQWJak//+nfTrwhbb8NXqB7qBv7d+5qt5eVecBZ9O7/PPngS8Bfw+c3TcmfktVPXmufoQ0aIZAaYiSPCvJG5IsbZ+X0buE5S+B/w5ckeTstu5bklw8w0M/BXgUeLjd7/fzh6zfDXxb3+f3Aj+W5MIki5I8IckLD/YlSdI8dSu9oPcLSU5sk5r9GHB9W38H8BNJnpjkO4BLD+6Y5LuTfE+7r/BrwD8AB9pZxd8DfivJGW3bJUkO3ncvjTxDoDRcjwDfA9ya5Gv0wt9dwBuq6kP0bky/vl3SeRfwohke95eB5wF/S2/Clw8esv7Xgf/SLnP5T1W1E1hDbyKavfTODP48/jdCkjSPVdXXgZfSGx+/RO9ewUvalTUAvwV8nd4fPzcB1/Xtfgq9sPcVepeQPgS8pa37RWAH8JdtDP4TYCaTzUgjIVWHXhUmSZIkSVqo/Cu/JEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA45YdgNzJXTTz+9li9fPuw2JElz7Pbbb/9SVfkQ5xlyfJSk7phujJyzEJjk3cBLgD1VdU6rnQb8IbAcuB94eVV9pa27gt6zWw4AP1dVH2v18+g9PPtk4CPA62oGU5ouX76ciYmJ2f1RkqR5J8nfDLuHUeL4KEndMd0YOZeXg14DrD6kdjmwtapWAFvbZ5KsBNYCZ7d9rkqyqO1zNbAeWNFehx5TkiRJkjRDcxYCq+oTwJcPKa+h96BO2vtFffXrq2pfVd1H7+Gcq5IsBk6pqlva2b9r+/aRJEmSJB2lQU8Mc2ZV7QJo72e0+hJgZ992k622pC0fWp9SkvVJJpJM7N27d1YblyRJkqSFYL7MDpopanWE+pSqamNVjVfV+NiYcwRIkiRJ0qEGHQJ3t0s8ae97Wn0SWNa33VLgwVZfOkVdkiRJknQMBh0CtwDr2vI64Ia++tokJyU5i94EMLe1S0YfSXJ+kgCX9O0jSdJISvLUJO9P8rkk25N8b5LTktyU5N72fmrf9lck2ZHkniQX9tXPS3JnW/f2NlZKknREcxYCk7wPuAV4ZpLJJJcCVwI/nORe4IfbZ6pqG7AZuBv4KHBZVR1oh3oN8E56k8X8NXDjXPUsSdKAvA34aFU9C3gOsB1n0JYkDcicPSewql4xzaoLptl+A7BhivoEcM4stiZJ0tAkOQV4AfCTAFX1deDrSdYAL2ybbQJuBn6Rvhm0gfuSHJxB+37aDNrtuAdn0PaPpZKkI5ovE8NIktQV3wbsBd6T5NNJ3pnkSczhDNrOni1J6mcIlCRpsE4AngdcXVXPBb5Gu/RzGsc9g7azZ0uS+s3Z5aALyXk/f+2wW9ACdvt/u2TYLUgarElgsqpubZ/fTy8E7k6yuKp2jcoM2o6PmkuOj9Lc8UygJEkDVFVfBHYmeWYrXUBvYjRn0JYkDYRnAiVJGryfBa5L8njg88BP0fvD7OY2m/YDwMXQm0E7ycEZtPdz+Aza1wAn05sQxklhJEmPyRAoSdKAVdUdwPgUq5xBW5I057wcVJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZKGIMn9Se5MckeSiVY7LclNSe5t76f2bX9Fkh1J7klyYV/9vHacHUneniTD+D2SpNFhCJQkaXh+oKrOrarx9vlyYGtVrQC2ts8kWQmsBc4GVgNXJVnU9rkaWA+saK/VA+xfkjSCDIGSJM0fa4BNbXkTcFFf/fqq2ldV9wE7gFVJFgOnVNUtVVXAtX37SJI0paGEwCT/Mcm2JHcleV+SJxzLJTCSJI2wAj6e5PYk61vtzKraBdDez2j1JcDOvn0nW21JWz60/k2SrE8ykWRi7969s/wzJEmjZuAhMMkS4OeA8ao6B1hE7xKXY7kERpKkUfX8qnoe8CLgsiQvOMK2U93nV0eof3OhamNVjVfV+NjY2LF1K0laMIZ1OegJwMlJTgCeCDzIUV4CM9h2JUmaXVX1YHvfA3yI3ti2u13iSXvf0zafBJb17b6U3tg52ZYPrUuSNK2Bh8Cq+gLwFuABYBfwt1X1cY7+EpjDeLmLJGkUJHlSkqccXAZ+BLgL2AKsa5utA25oy1uAtUlOSnIWvQlgbmvj5SNJzm+zgl7St48kSVM6YdBf2O71WwOcBTwM/M8krzzSLlPUDrvUBXqXuwAbAcbHx6fcRpKkeeBM4EPtaQ4nAH9QVR9N8lfA5iSX0vtj6cUAVbUtyWbgbmA/cFlVHWjHeg1wDXAycGN7SZI0rYGHQOCHgPuqai9Akg8C30e7BKaqds3wEhhJkkZSVX0eeM4U9YeAC6bZZwOwYYr6BHDObPcoSVq4hnFP4APA+Ume2C5duQDYzlFeAjPgniVJkiRpQRj4mcCqujXJ+4FP0buk5dP0LuF8Mkd/CYwkSZIk6SgM43JQqupNwJsOKe/jKC+BkSRJkiQdnWE9IkKSJEmSNASGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEnSECRZlOTTST7cPp+W5KYk97b3U/u2vSLJjiT3JLmwr35ekjvburcnyTB+iyRptBgCJUkajtcB2/s+Xw5sraoVwNb2mSQrgbXA2cBq4Koki9o+VwPrgRXttXowrUuSRpkhUJKkAUuyFPhR4J195TXApra8Cbior359Ve2rqvuAHcCqJIuBU6rqlqoq4Nq+fSRJmpYhUJKkwftt4BeAb/TVzqyqXQDt/YxWXwLs7NtustWWtOVD64dJsj7JRJKJvXv3zsoPkCSNLkOgJEkDlOQlwJ6qun2mu0xRqyPUDy9Wbayq8aoaHxsbm+HXSpIWqhOG3YAkSR3zfOClSV4MPAE4Jcl7gd1JFlfVrnap5562/SSwrG//pcCDrb50irokSUfkmUBJkgaoqq6oqqVVtZzehC9/WlWvBLYA69pm64Ab2vIWYG2Sk5KcRW8CmNvaJaOPJDm/zQp6Sd8+kiRNyzOBkiTND1cCm5NcCjwAXAxQVduSbAbuBvYDl1XVgbbPa4BrgJOBG9tLkqQjMgRKkjQkVXUzcHNbfgi4YJrtNgAbpqhPAOfMXYeSpIXIy0ElSZIkqUMMgZIkSZLUIYZASZIkSeqQoYTAJE9N8v4kn0uyPcn3JjktyU1J7m3vp/Ztf0WSHUnuSXLhMHqWJEmSpIVgWGcC3wZ8tKqeBTwH2A5cDmytqhXA1vaZJCvpTaF9NrAauCrJoqF0LUmSJEkjbuAhMMkpwAuAdwFU1der6mFgDbCpbbYJuKgtrwGur6p9VXUfsANYNcieJUmSJGmhGMaZwG8D9gLvSfLpJO9M8iTgzPbgW9r7GW37JcDOvv0nW+0wSdYnmUgysXfv3rn7BZIkSZI0ooYRAk8AngdcXVXPBb5Gu/RzGpmiVlNtWFUbq2q8qsbHxsaOv1NJkiRJWmCGEQIngcmqurV9fj+9ULg7yWKA9r6nb/tlffsvBR4cUK+SJEmStKAMPARW1ReBnUme2UoXAHcDW4B1rbYOuKEtbwHWJjkpyVnACuC2AbYsSZIkSQvGCUP63p8FrkvyeODzwE/RC6Sbk1wKPABcDFBV25JsphcU9wOXVdWB4bQtSZIkSaNtKCGwqu4AxqdYdcE0228ANsxlT5IkSZLUBcN6TqAkSZIkaQgMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR0yoxCYZOtMapIkdYnjoyRpFB3xOYFJngA8ETg9yalA2qpTgKfNcW+SJM1Ljo+SpFH2WA+LfzXwenoD2u388yD3VeAdc9eWJEnzmuOjJGlkHTEEVtXbgLcl+dmq+p0B9SRJ0rzm+ChJGmWPdSYQgKr6nSTfByzv36eqrp2jviRJmvccHyVJo2hGITDJ7wPfDtwBHGjlAhzkJEmd5fgoSRpFMwqBwDiwsqpqLpuRJGnEOD5KkkbOTJ8TeBfwrXPZiCRJI8jxUZI0cmZ6JvB04O4ktwH7Dhar6qVz0pUkSaPB8VGSNHJmGgLfPJdNSJI0ot487AYkSTpaM50d9M/nuhFJkkaN46MkaRTNdHbQR+jNdgbweOBE4GtVdcpcNSZJ0nzn+ChJGkUzPRP4lP7PSS4CVs1FQ5IkjQrHR0nSKJrp7KDfpKr+CPjB2W1FkqTRNpPxMckTktyW5DNJtiX55VY/LclNSe5t76f27XNFkh1J7klyYV/9vCR3tnVvT5K5+m2SpIVjppeD/kTfx8fRey6Sz0SSJHXaMY6P+4AfrKpHk5wIfDLJjcBPAFur6soklwOXA7+YZCWwFjgbeBrwJ0m+s6oOAFcD64G/BD4CrAZunL1fKElaiGY6O+iP9S3vB+4H1sx6N5IkjZajHh/bg+UfbR9PbK9q+72w1TcBNwO/2OrXV9U+4L4kO4BVSe4HTqmqWwCSXAtchCFQkvQYZnpP4E/NdSOSJI2aYx0fkywCbge+A3hHVd2a5Myq2tWOuyvJGW3zJfTO9B002Wr/2JYPrU/1fevpnTHk6U9/+rG0LElaQGZ0T2CSpUk+lGRPkt1JPpBk6Vw3J0nSfHas42NVHaiqc4Gl9M7qnXOkr5nqEEeoT/V9G6tqvKrGx8bGHqs9SdICN9OJYd4DbKF3L8IS4I9bTZKkLjuu8bGqHqZ32edqYHeSxQDtfU/bbBJY1rfbUuDBVl86RV2SpCOaaQgcq6r3VNX+9roG8E+JkqSuO+rxMclYkqe25ZOBHwI+Ry9MrmubrQNuaMtbgLVJTkpyFrACuK1dOvpIkvPbrKCX9O0jSdK0ZjoxzJeSvBJ4X/v8CuChuWlJkqSRcSzj42JgU7sv8HHA5qr6cJJbgM1JLgUeAC4GqKptSTYDd9ObfOayNjMowGuAa4CT6U0I46QwkqTHNNMQ+NPA7wK/Re9+g78AnCxGktR1Rz0+VtVngedOUX8IuGCafTYAG6aoTwBHup9QkqTDzDQE/iqwrqq+Ar0H2gJvoTf4SZLUVY6PkqSRM9N7Ar/r4AAHUFVfZoq/YkqS1DGOj5KkkTPTEPi4JKce/ND+0jnTs4iSJC1Ujo+SpJEz04HqN4G/SPJ+evc8vJwp7k2QJKljHB8lSSNnRiGwqq5NMgH8IL2H0/5EVd09p51JkjTPOT5KkkbRjC9ZaYOaA5skSX0cHyVJo2am9wRKkiRJkhYAQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHDC0EJlmU5NNJPtw+n5bkpiT3tvdT+7a9IsmOJPckuXBYPUuSJEnSqBvmmcDXAdv7Pl8ObK2qFcDW9pkkK4G1wNnAauCqJIsG3KskSZIkLQhDCYFJlgI/Cryzr7wG2NSWNwEX9dWvr6p9VXUfsANYNaBWJUmSJGlBGdaZwN8GfgH4Rl/tzKraBdDez2j1JcDOvu0mW+0wSdYnmUgysXfv3llvWpIkSZJG3cBDYJKXAHuq6vaZ7jJFrabasKo2VtV4VY2PjY0dc4+SJEmStFCdMITvfD7w0iQvBp4AnJLkvcDuJIuraleSxcCetv0ksKxv/6XAgwPtWJIkSZIWiIGfCayqK6pqaVUtpzfhy59W1SuBLcC6ttk64Ia2vAVYm+SkJGcBK4DbBty2JEmSJC0IwzgTOJ0rgc1JLgUeAC4GqKptSTYDdwP7gcuq6sDw2pQkSZKk0TXUEFhVNwM3t+WHgAum2W4DsGFgjUmSJEnSAjXM5wRKkiRJkgbMEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1yFAfFi9JkiSNkgd+5V8OuwUtcE//pTvn/Ds8EyhJ0gAlWZbkz5JsT7Ityeta/bQkNyW5t72f2rfPFUl2JLknyYV99fOS3NnWvT1JhvGbJEmjxRAoSdJg7QfeUFXPBs4HLkuyErgc2FpVK4Ct7TNt3VrgbGA1cFWSRe1YVwPrgRXttXqQP0SSNJoMgZIkDVBV7aqqT7XlR4DtwBJgDbCpbbYJuKgtrwGur6p9VXUfsANYlWQxcEpV3VJVBVzbt48kSdMyBEqSNCRJlgPPBW4FzqyqXdALisAZbbMlwM6+3SZbbUlbPrQ+1fesTzKRZGLv3r2z+hskSaPHEChJ0hAkeTLwAeD1VfXVI206Ra2OUD+8WLWxqsaranxsbOzom5UkLSiGQEmSBizJifQC4HVV9cFW3t0u8aS972n1SWBZ3+5LgQdbfekUdUmSjsgQKEnSALUZPN8FbK+qt/at2gKsa8vrgBv66muTnJTkLHoTwNzWLhl9JMn57ZiX9O0jSdK0fE6gJEmD9XzgVcCdSe5otTcCVwKbk1wKPABcDFBV25JsBu6mN7PoZVV1oO33GuAa4GTgxvaSJOmIDIGSJA1QVX2Sqe/nA7hgmn02ABumqE8A58xed5KkLvByUEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShww8BCZZluTPkmxPsi3J61r9tCQ3Jbm3vZ/at88VSXYkuSfJhYPuWZIkSZIWimGcCdwPvKGqng2cD1yWZCVwObC1qlYAW9tn2rq1wNnAauCqJIuG0LckSZIkjbyBh8Cq2lVVn2rLjwDbgSXAGmBT22wTcFFbXgNcX1X7quo+YAewaqBNS5IkSdICMdR7ApMsB54L3AqcWVW7oBcUgTPaZkuAnX27TbbaVMdbn2QiycTevXvnrG9JkiRJGlVDC4FJngx8AHh9VX31SJtOUaupNqyqjVU1XlXjY2Njs9GmJEmSJC0oQwmBSU6kFwCvq6oPtvLuJIvb+sXAnlafBJb17b4UeHBQvUqSJEnSQjKM2UEDvAvYXlVv7Vu1BVjXltcBN/TV1yY5KclZwArgtkH1K0mSJEkLyQlD+M7nA68C7kxyR6u9EbgS2JzkUuAB4GKAqtqWZDNwN72ZRS+rqgMD71qSJEmSFoCBh8Cq+iRT3+cHcME0+2wANsxZU5IkSZLUEcM4EyhpBDzwK/9y2C1oAXv6L9057BaGKsm7gZcAe6rqnFY7DfhDYDlwP/DyqvpKW3cFcClwAPi5qvpYq58HXAOcDHwEeF1VTTl5miRJBw31ERGSJHXUNcDqQ2qXA1uragWwtX0myUpgLXB22+eqJIvaPlcD6+ndL79iimNKknQYQ6AkSQNWVZ8AvnxIeQ2wqS1vAi7qq19fVfuq6j5gB7CqzaR9SlXd0s7+Xdu3jyRJ0zIESpI0P5xZVbsA2vsZrb4E2Nm33WSrLWnLh9YPk2R9kokkE3v37p31xiVJo8UQKEnS/DbVZGp1hPrhxaqNVTVeVeNjY2Oz2pwkafQYAiVJmh92t0s8ae97Wn0SWNa33VLgwVZfOkVdkqQjMgRKkjQ/bAHWteV1wA199bVJTkpyFr0JYG5rl4w+kuT8JAEu6dtHkqRp+YgISZIGLMn7gBcCpyeZBN4EXAlsTnIp8ABwMUBVbUuyGbgb2A9cVlUH2qFewz8/IuLG9pIk6YgMgZIkDVhVvWKaVRdMs/0GYMMU9QngnFlsTZLUAV4OKkmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVCSJEmSOsQQKEmSJEkdYgiUJEmSpA4xBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqkJEJgUlWJ7knyY4klw+7H0mS5gPHR0nS0RqJEJhkEfAO4EXASuAVSVYOtytJkobL8VGSdCxGIgQCq4AdVfX5qvo6cD2wZsg9SZI0bI6PkqSjdsKwG5ihJcDOvs+TwPcculGS9cD69vHRJPcMoDcd7nTgS8NuYlTkLeuG3YJmh//uj8abMptHe8ZsHmzEOD6OFv87cRQcHxcU/+0fjQGMkaMSAqf6X6IOK1RtBDbOfTs6kiQTVTU+7D6kQfLfvYbE8XGE+N8JdZX/9uefUbkcdBJY1vd5KfDgkHqRJGm+cHyUJB21UQmBfwWsSHJWkscDa4EtQ+5JkqRhc3yUJB21kbgctKr2J3kt8DFgEfDuqto25LY0PS85Uhf5714D5/g4cvzvhLrKf/vzTKoOu3VAkiRJkrRAjcrloJIkSZKkWWAIlCRJkqQOMQRq1iRZneSeJDuSXD7sfqRBSPLuJHuS3DXsXiTNX46R6iLHyPnLEKhZkWQR8A7gRcBK4BVJVg63K2kgrgFWD7sJSfOXY6Q67BocI+clQ6BmyypgR1V9vqq+DlwPrBlyT9Kcq6pPAF8edh+S5jXHSHWSY+T8ZQjUbFkC7Oz7PNlqkiR1nWOkpHnFEKjZkilqPn9EkiTHSEnzjCFQs2USWNb3eSnw4JB6kSRpPnGMlDSvGAI1W/4KWJHkrCSPB9YCW4bckyRJ84FjpKR5xRCoWVFV+4HXAh8DtgObq2rbcLuS5l6S9wG3AM9MMpnk0mH3JGl+cYxUVzlGzl+p8pJ0SZIkSeoKzwRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQmueSPPoY65cnuesoj3lNkpcdX2eSJA2P46N07AyBkiRJktQhhkBpRCR5cpKtST6V5M4ka/pWn5BkU5LPJnl/kie2fc5L8udJbk/ysSSLh9S+JElzwvFROnqGQGl0/APw41X1POAHgN9MkrbumcDGqvou4KvAzyQ5Efgd4GVVdR7wbmDDEPqWJGkuOT5KR+mEYTcgacYC/FqSFwDfAJYAZ7Z1O6vq/7Tl9wI/B3wUOAe4qY2Fi4BdA+1YkqS55/goHSVDoDQ6/i0wBpxXVf+Y5H7gCW1dHbJt0RsUt1XV9w6uRUmSBs7xUTpKXg4qjY5vAfa0Ae4HgGf0rXt6koOD2SuATwL3AGMH60lOTHL2QDuWJGnuOT5KR8kQKI2O64DxJBP0/ur5ub5124F1ST4LnAZcXVVfB14G/EaSzwB3AN832JYlSZpzjo/SUUrVoWfJJUmSJEkLlWcCJUmSJKlDDIGSJEmS1CGGQEmSJEnqEEOgJEmSJHWIIVAaAUnemOSdR1h/f5IfmqPvvjHJuhluO2d9SJJ0PJJck+S/tuUXJpkcdk/SsPiweGkWtAfTngkcAL4GfAT42ap6dDaOX1W/NhvHeSxJ3gx8R1W9su+7XzSI75YkabYkuRl4DvCtVbVvyO1I845nAqXZ82NV9WTgecB3A/+lf2US/+giSdIcS7Ic+FdAAS8dbjfS/GQIlGZZVX0BuBE4J0kluSzJvcC9AElekuSOJA8n+Ysk33Vw3yS/mOQLSR5Jck+SC1r9zUne27fdq5L8TZKHkvzn/u9P8rgklyf567Z+c5LT2rrlrad1SR5I8qWD+ydZDbwR+DdJHm0P0CXJzUn+XVv+9iR/2o77pSTXJXnq3P2vKUnSUbsE+EvgGmBGtzNIXWMIlGZZkmXAi4FPt9JFwPcAK5M8D3g38GrgXwD/A9iS5KQkzwReC3x3VT0FuBC4f4rjrwSuBl4FPK0dZ2nfJj/XvvNft/VfAd5xyGG+H3gmcAHwS0meXVUfBX4N+MOqenJVPWeqnwf8ejvus4FlwJtn8D+LJEmDcglwXXtdmOTMIfcjzTuGQGn2/FGSh4FPAn9OL1AB/HpVfbmq/h7498D/qKpbq+pAVW0C9gHn07uf8CR6YfHEqrq/qv56iu95GfDhqvpEu8/h/wG+0bf+1cB/rqrJtv7NwMsOuRz1l6vq76vqM8Bn6N038ZiqakdV3VRV+6pqL/BWemFTkqShS/L9wDOAzVV1O/DXwP893K6k+ccQKM2ei6rqqVX1jKr6mRb6AHb2bfMM4A3tUtCHW2hcBjytqnYAr6cX2vYkuT7J06b4nqf1H7OqvgY8dMh3fKjv+NvpBcz+v4R+sW/574Anz+QHJjmj9fWFJF8F3gucPpN9JUkagHXAx6vqS+3zH+AlodJhDIHS3Ku+5Z3AhhYWD76eWFXvA6iqP6iqg3/FLOA3pjjeLnrBEYAkT6R3SWj/d7zokO94QrtX8Wh6ncqvt22+q6pOAV5J7xJRSZKGKsnJwMuBf53ki0m+CPxH4DlJZnTFi9QVhkBpsH4P+A9Jvic9T0ryo0mekuSZSX4wyUnAPwB/T+8M3qHeD7wkyfcneTzwK3zz/y3/d2BDkmcAJBlLsmaG/e0GlieZ7r8NTwEeBR5OsgT4+RkeV5KkuXYRvXFzJXBuez0b+N/07hOU1BgCpQGqqgl69wX+Lr0JW3YAP9lWnwRcCXyJ3uWaZ9CbrfPQY2wDLqN3icuudpz+B96+DdgCfDzJI/RmSPueGbb4P9v7Q0k+NcX6X6b3CIy/Bf4X8MEZHleSpLm2DnhPVT1QVV88+KI35v5bfD629E9S9VhXf0mSJEmSFgrPBEqSJElShww8BCZ5QpLbknwmybYkv9zqb24zDt7RXi/u2+eKJDvaw7MvHHTPkiRJkrRQDPxy0CQBnlRVjyY5kd4z1V4HrAYeraq3HLL9SuB9wCp6U+P/CfCdVTXVhBmSJEmSpCMY+JnA6nm0fTyxvY6URNcA17eHU99HbyKNVXPcpiRJkiQtSEOZJSnJIuB24DuAd1TVrUleBLw2ySXABPCGqvoKsITe7IYHTbbaVMddD6wHeNKTnnTes571rDn8FZKk+eD222//UlWNDbuPUXH66afX8uXLh92GJGkAphsjhxIC26Wc5yZ5KvChJOcAVwO/Su+s4K8Cvwn8NFM/iHrKM4dVtRHYCDA+Pl4TExOz37wkaV5J8jfD7mGULF++HMdHSeqG6cbIoc4OWlUPAzcDq6tqd1UdqKpv0Hug9sFLPieBZX27LQUeHGSfkiRJkrRQDGN20LF2BpAkJwM/BHwuyeK+zX4cuKstbwHWJjkpyVnACuC2AbYsSZIkSQvGMC4HXQxsavcFPg7YXFUfTvL7Sc6ld6nn/cCrAapqW5LNwN3AfuAyZwaVJEmSpGMz8BBYVZ8FnjtF/VVH2GcDsGEu+5IkSZKkLhjqPYGSJEmSpMEyBEqSJElShxgCJUmSJKlDDIGSJEmS1CGGQEmSJEnqkGE8ImLknPfz1w67BS1gt/+3S4bdgiQdE8dHzSXHR2nueCZQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJGrAkz0xyR9/rq0len+S0JDclube9n9q3zxVJdiS5J8mFffXzktzZ1r09SYbzqyRJo8IQKEnSgFXVPVV1blWdC5wH/B3wIeByYGtVrQC2ts8kWQmsBc4GVgNXJVnUDnc1sB5Y0V6rB/hTJEkjyBAoSdJwXQD8dVX9DbAG2NTqm4CL2vIa4Pqq2ldV9wE7gFVJFgOnVNUtVVXAtX37SJI0JUOgJEnDtRZ4X1s+s6p2AbT3M1p9CbCzb5/JVlvSlg+tf5Mk65NMJJnYu3fvLLcvSRo1hkBJkoYkyeOBlwL/87E2naJWR6h/c6FqY1WNV9X42NjY0TcqSVpQDIGSJA3Pi4BPVdXu9nl3u8ST9r6n1SeBZX37LQUebPWlU9QlSZqWIVCSpOF5Bf98KSjAFmBdW14H3NBXX5vkpCRn0ZsA5rZ2yegjSc5vs4Je0rePJElTOmHYDUiS1EVJngj8MPDqvvKVwOYklwIPABcDVNW2JJuBu4H9wGVVdaDt8xrgGuBk4Mb2kiRpWoZASZKGoKr+DvgXh9Qeojdb6FTbbwA2TFGfAM6Zix4lSQuTl4NKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHTLwEJjkCUluS/KZJNuS/HKrn5bkpiT3tvdT+/a5IsmOJPckuXDQPUuSJEnSQjGMM4H7gB+squcA5wKrk5wPXA5sraoVwNb2mSQrgbXA2cBq4Koki4bQtyRJkiSNvIGHwOp5tH08sb0KWANsavVNwEVteQ1wfVXtq6r7gB3AqsF1LEmSJEkLx1DuCUyyKMkdwB7gpqq6FTizqnYBtPcz2uZLgJ19u0+22lTHXZ9kIsnE3r1756x/SZIkSRpVQwmBVXWgqs4FlgKrkpxzhM0z1SGmOe7GqhqvqvGxsbFZ6FSSJEmSFpahzg5aVQ8DN9O71293ksUA7X1P22wSWNa321LgwcF1KUmSJEkLxzBmBx1L8tS2fDLwQ8DngC3AurbZOuCGtrwFWJvkpCRnASuA2wbatCRJkiQtECcM4TsXA5vaDJ+PAzZX1YeT3AJsTnIp8ABwMUBVbUuyGbgb2A9cVlUHhtC3JEmSJI28gYfAqvos8Nwp6g8BF0yzzwZgwxy3JkmSJEkL3lDvCZQkSZIkDZYhUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIGLMlTk7w/yeeSbE/yvUlOS3JTknvb+6l921+RZEeSe5Jc2Fc/L8mdbd3bk2Q4v0iSNEoMgZIkDd7bgI9W1bOA5wDbgcuBrVW1AtjaPpNkJbAWOBtYDVyVZFE7ztXAemBFe60e5I+QJI0mQ6AkSQOU5BTgBcC7AKrq61X1MLAG2NQ22wRc1JbXANdX1b6qug/YAaxKshg4papuqaoCru3bR5KkaRkCJUkarG8D9gLvSfLpJO9M8iTgzKraBdDez2jbLwF29u0/2WpL2vKh9cMkWZ9kIsnE3r17Z/fXSJJGjiFQkqTBOgF4HnB1VT0X+Brt0s9pTHWfXx2hfnixamNVjVfV+NjY2NH2K0laYAyBkiQN1iQwWVW3ts/vpxcKd7dLPGnve/q2X9a3/1LgwVZfOkVdkqQjMgRKkjRAVfVFYGeSZ7bSBcDdwBZgXautA25oy1uAtUlOSnIWvQlgbmuXjD6S5Pw2K+glfftIkjStE4bdgCRJHfSzwHVJHg98Hvgpen+Y3ZzkUuAB4GKAqtqWZDO9oLgfuKyqDrTjvAa4BjgZuLG9JEk6IkOgJEkDVlV3AONTrLpgmu03ABumqE8A58xqc5KkBc/LQSVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6pCBh8Aky5L8WZLtSbYleV2rvznJF5Lc0V4v7tvniiQ7ktyT5MJB9yxJkiRJC8UJQ/jO/cAbqupTSZ4C3J7kprbut6rqLf0bJ1kJrAXOBp4G/EmS76yqAwPtWpIkSZIWgIGfCayqXVX1qbb8CLAdWHKEXdYA11fVvqq6D9gBrJr7TiVJkiRp4RnqPYFJlgPPBW5tpdcm+WySdyc5tdWWADv7dptkmtCYZH2SiSQTe/funau2JUmSJGlkDS0EJnky8AHg9VX1VeBq4NuBc4FdwG8e3HSK3WuqY1bVxqoar6rxsbGx2W9akiRJkkbcUEJgkhPpBcDrquqDAFW1u6oOVNU3gN/jny/5nASW9e2+FHhwkP1KkiRJ0kIxjNlBA7wL2F5Vb+2rL+7b7MeBu9ryFmBtkpOSnAWsAG4bVL+SJEmStJAMY3bQ5wOvAu5MckervRF4RZJz6V3qeT/waoCq2pZkM3A3vZlFL3NmUEmSJEk6NgMPgVX1Saa+z+8jR9hnA7BhzpqSJEmSpI4Y6uygkiRJkqTBMgRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkoYgyf1J7kxyR5KJVjstyU1J7m3vp/Ztf0WSHUnuSXJhX/28dpwdSd7eHsUkSdK0DIGSJA3PD1TVuVU13j5fDmytqhXA1vaZJCuBtcDZwGrgqiSL2j5XA+vpPUd3RVsvSdK0DIGSJM0fa4BNbXkTcFFf/fqq2ldV9wE7gFVJFgOnVNUtVVXAtX37SJI0JUOgJEnDUcDHk9yeZH2rnVlVuwDa+xmtvgTY2bfvZKstacuH1r9JkvVJJpJM7N27d5Z/hiRp1Az8YfGSJAmA51fVg0nOAG5K8rkjbDvVfX51hPo3F6o2AhsBxsfHD1svSeoWzwRKkjQEVfVge98DfAhYBexul3jS3ve0zSeBZX27LwUebPWlU9QlSZqWIVCSpAFL8qQkTzm4DPwIcBewBVjXNlsH3NCWtwBrk5yU5Cx6E8Dc1i4ZfSTJ+W1W0Ev69pEkaUpeDipJ0uCdCXyoPc3hBOAPquqjSf4K2JzkUuAB4GKAqtqWZDNwN7AfuKyqDrRjvQa4BjgZuLG9JEmaliFQkqQBq6rPA8+Zov4QcME0+2wANkxRnwDOme0eJUkLl5eDSpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdcjAQ2CSZUn+LMn2JNuSvK7VT0tyU5J72/upfftckWRHknuSXDjoniVJkiRpoRjGmcD9wBuq6tnA+cBlSVYClwNbq2oFsLV9pq1bC5wNrAauSrJoCH1LkiRJ0sgbeAisql1V9am2/AiwHVgCrAE2tc02ARe15TXA9VW1r6ruA3YAqwbatCRJkiQtEEO9JzDJcuC5wK3AmVW1C3pBETijbbYE2Nm322SrTXW89Ukmkkzs3bt3zvqWJEmSpFE1tBCY5MnAB4DXV9VXj7TpFLWaasOq2lhV41U1PjY2NhttSpIkSdKCMpQQmOREegHwuqr6YCvvTrK4rV8M7Gn1SWBZ3+5LgQcH1askSZIkLSTDmB00wLuA7VX11r5VW4B1bXkdcENffW2Sk5KcBawAbhtUv5IkSZK0kJwwhO98PvAq4M4kd7TaG4Ergc1JLgUeAC4GqKptSTYDd9ObWfSyqjow8K4lSZIkaQEYeAisqk8y9X1+ABdMs88GYMOcNSVJkiRJHXFcl4Mm2TqTmiRJC5HjoCRpFB1TCEzyhCSnAacnOTXJae21HHjarHYoSdI8MxvjYJJFST6d5MPt82lJbkpyb3s/tW/bK5LsSHJPkgv76uclubOte3u7716SpCM61jOBrwZuB57V3g++bgDeMTutSZI0b83GOPg6YHvf58uBrVW1AtjaPpNkJbAWOBtYDVyVZFHb52pgPb1J01a09ZIkHdExhcCqeltVnQX8p6r6tqo6q72eU1W/O8s9SpI0rxzvOJhkKfCjwDv7ymuATW15E3BRX/36qtpXVfcBO4BV7XFKp1TVLVVVwLV9+0iSNK3jmhimqn4nyfcBy/uPVVXXHmdfkiTNe8cxDv428AvAU/pqZ1bVrrb/riRntPoS4C/7tptstX9sy4fWD5NkPb0zhjz96U9/jNYkSQvdcYXAJL8PfDtwB3DwsQ0H/xopSdKCdizjYJKXAHuq6vYkL5zJ10xRqyPUDy9WbQQ2AoyPj0+5jSSpO473ERHjwMp2GYokSV1zLOPg84GXJnkx8ATglCTvBXYnWdzOAi4G9rTtJ4FlffsvBR5s9aVT1CVJOqLjekQEcBfwrbPRiCRJI+iox8GquqKqllbVcnoTvvxpVb0S2AKsa5utozfJDK2+NslJSc6iNwHMbe3S0UeSnN9mBb2kbx9JkqZ1vGcCTwfuTnIbsO9gsapeepzHlSRpFMzmOHglsDnJpcADwMXtWNuSbAbuBvYDl1XVwUtPXwNcA5wM3NhekiQd0fGGwDfPRhOSJI2oNx/PzlV1M3BzW34IuGCa7TYAG6aoTwDnHE8PkqTuOd7ZQf98thqRJGnUOA5KkkbR8c4O+gj/PBPZ44ETga9V1SnH25gkSfOd46AkaRQd75nA/ucbkeQiYNXxHFOSpFHhOChJGkXHOzvoN6mqPwJ+cDaPKUnSqHAclCSNguO9HPQn+j4+jt7zknxmoCSpExwHJUmj6HhnB/2xvuX9wP3AmuM8piRJo8JxUJI0co73nsCfmq1GJEkaNY6DkqRRdFz3BCZZmuRDSfYk2Z3kA0mWzlZzkiTNZ46DkqRRdLwTw7wH2AI8DVgC/HGrSZLUBY6DkqSRc7whcKyq3lNV+9vrGmBsFvqSJGkUOA5KkkbO8YbALyV5ZZJF7fVK4KHZaEySpBHgOChJGjnHGwJ/Gng58EVgF/AywJvkJUld4TgoSRo5x/uIiF8F1lXVVwCSnAa8hd6gKEnSQuc4KEkaOcd7JvC7Dg58AFX1ZeC5x3lMSZJGheOgJGnkHG8IfFySUw9+aH8BPd6zi5IkjQrHQUnSyDnegeo3gb9I8n6g6N0XseG4u5IkaTQ4DkqSRs5xnQmsqmuB/wvYDewFfqKqfv+x9kvy7vZg3bv6am9O8oUkd7TXi/vWXZFkR5J7klx4PD1LkjRbjnUclCRpmI77kpWquhu4+yh3uwb4XeDaQ+q/VVVv6S8kWQmsBc6m9zDeP0nynVV14Ng6liRp9hzjOChJ0tAc7z2Bx6SqPgF8eYabrwGur6p9VXUfsANYNWfNSZIkSdICNpQQeASvTfLZdrnowRvtlwA7+7aZbLXDJFmfZCLJxN69e+e6V0mSJEkaOfMpBF4NfDtwLr0H7v5mq2eKbWuqA1TVxqoar6rxsbGxOWlSkiRJkkbZvAmBVbW7qg5U1TeA3+OfL/mcBJb1bboUeHDQ/UmSJEnSQjBvQmCSxX0ffxw4OHPoFmBtkpOSnAWsAG4bdH+SJEmStBAM5YG2Sd4HvBA4Pckk8CbghUnOpXep5/3AqwGqaluSzfRmXtsPXObMoJIkSZJ0bIYSAqvqFVOU33WE7Tfgw3clSQtAkicAnwBOojcOv7+q3pTkNOAPgeX0/hj68qr6StvnCuBS4ADwc1X1sVY/j95jl04GPgK8rqqmvG9ekqSD5s3loJIkdcQ+4Aer6jn0JkNbneR84HJga1WtALa2z4c+L3c1cFWSRe1YVwPr6d0qsaKtlyTpiAyBkiQNUPU82j6e2F5F77m4m1p9E3BRW57yebntXvpTquqWdvbv2r59JEmaliFQkqQBS7IoyR3AHuCmqroVOLOqdgG09zPa5tM9L3dJWz60PtX3+RxdSdI/MQRKkjRg7ZFI59J77NGqJOccYfPpnpfrc3QlScfEEChJ0pBU1cPAzfTu5dt98HFJ7X1P22y65+VOtuVD65IkHZEhUJKkAUoyluSpbflk4IeAz9F7Lu66ttk64Ia2POXzctslo48kOT9JgEv69pEkaVpDeUSEJEkdthjY1Gb4fBywuao+nOQWYHOSS4EHgIvhMZ+X+xr++RERN7aXJElHZAiUJGmAquqzwHOnqD8EXDDNPlM+L7eqJoAj3U8oSdJhvBxUkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhJwy7AUmSJGlUPPAr/3LYLWiBe/ov3Tnn3+GZQEmSJEnqEEOgJEmSJHWIIVCSJEmSOmQoITDJu5PsSXJXX+20JDclube9n9q37ookO5Lck+TCYfQsSZIkSQvBsM4EXgOsPqR2ObC1qlYAW9tnkqwE1gJnt32uSrJocK1KkiRJ0sIxlBBYVZ8AvnxIeQ2wqS1vAi7qq19fVfuq6j5gB7BqEH1KkiRJ0kIzn+4JPLOqdgG09zNafQmws2+7yVY7TJL1SSaSTOzdu3dOm5UkSZKkUTQKzwnMFLWaasOq2ghsBBgfH59yG0kz43OQNJcG8QwkSZI0tfl0JnB3ksUA7X1Pq08Cy/q2Wwo8OODeJEmSJGlBmE8hcAuwri2vA27oq69NclKSs4AVwG1D6E+SpOOWZFmSP0uyPcm2JK9r9aOeJTvJeUnubOvenmSqq2ckSfomw3pExPuAW4BnJplMcilwJfDDSe4Ffrh9pqq2AZuBu4GPApdV1YFh9C1J0izYD7yhqp4NnA9c1mbCPpZZsq8G1tP7A+kKDp95W5KkwwzlnsCqesU0qy6YZvsNwIa560iSpMFok58dnAjtkSTb6U14tgZ4YdtsE3Az8Iv0zZIN3JdkB7Aqyf3AKVV1C0CSa+nNrH3joH6LJGk0zafLQSVJ6pQky4HnArdy9LNkL2nLh9an+h5nz5Yk/RNDoCRJQ5DkycAHgNdX1VePtOkUtTpC/fBi1caqGq+q8bGxsaNvVpK0oBgCJUkasCQn0guA11XVB1v5aGfJnmzLh9YlSToiQ6AkSQPUZvB8F7C9qt7at+qoZslul4w+kuT8dsxL+vaRJGlao/CweEmSFpLnA68C7kxyR6u9kd6s2JvbjNkPABdDb5bsJAdnyd7PN8+S/RrgGuBkehPCOCmMJOkxGQIlSRqgqvokU9/PB0c5S3ZVTQDnzF53kqQu8HJQSZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjEESpIkSVKHGAIlSZIkqUMMgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJQkSZKkDjlh2A0cKsn9wCPAAWB/VY0nOQ34Q2A5cD/w8qr6yrB6lCRJkqRRNV/PBP5AVZ1bVePt8+XA1qpaAWxtnyVJkiRJR2m+hsBDrQE2teVNwEXDa0WSpOOT5N1J9iS5q692WpKbktzb3k/tW3dFkh1J7klyYV/9vCR3tnVvT5JB/xZJ0uiZjyGwgI8nuT3J+lY7s6p2AbT3M6baMcn6JBNJJvbu3TugdiVJOmrXAKsPqU151UuSlcBa4Oy2z1VJFrV9rgbWAyva69BjSpJ0mPkYAp9fVc8DXgRcluQFM92xqjZW1XhVjY+Njc1dh5IkHYeq+gTw5UPK0131sga4vqr2VdV9wA5gVZLFwClVdUtVFXAtXikjSZqBeRcCq+rB9r4H+BCwCtjdBjva+57hdShJ0pyY7qqXJcDOvu0mW21JWz60fhivlJEk9ZtXITDJk5I85eAy8CPAXcAWYF3bbB1ww3A6lCRp4Ka6z6+OUD+86JUykqQ+8+0REWcCH2r3tZ8A/EFVfTTJXwGbk1wKPABcPMQeJUmaC7uTLK6qXYdc9TIJLOvbbinwYKsvnaIuSdIRzasQWFWfB54zRf0h4ILBdyRJ0sAcvOrlSr75qpctwB8keSvwNHoTwNxWVQeSPJLkfOBW4BLgdwbftiRp1MyrEChJUhckeR/wQuD0JJPAm+iFv8OueqmqbUk2A3cD+4HLqupAO9Rr6M00ejJwY3tJknREhkBJkgasql4xzaopr3qpqg3AhinqE8A5s9iaJKkD5tXEMJIkSZKkuWUIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQwyBkiRJktQhhkBJkiRJ6hBDoCRJkiR1iCFQkiRJkjpkZEJgktVJ7kmyI8nlw+5HkqT5wPFRknS0RiIEJlkEvAN4EbASeEWSlcPtSpKk4XJ8lCQdi5EIgcAqYEdVfb6qvg5cD6wZck+SJA2b46Mk6aidMOwGZmgJsLPv8yTwPYdulGQ9sL59fDTJPQPoTYc7HfjSsJsYFXnLumG3oNnhv/uj8abM5tGeMZsHGzGOj6PF/04cBcfHBcV/+0djAGPkqITAqf6XqMMKVRuBjXPfjo4kyURVjQ+7D2mQ/HevIXF8HCH+d0Jd5b/9+WdULgedBJb1fV4KPDikXiRJmi8cHyVJR21UQuBfASuSnJXk8cBaYMuQe5IkadgcHyVJR20kLgetqv1JXgt8DFgEvLuqtg25LU3PS47URf6718A5Po4c/zuhrvLf/jyTqsNuHZAkSZIkLVCjcjmoJEmSJGkWGAIlSZIkqUMMgZo1SVYnuSfJjiSXD7sfaRCSvDvJniR3DbsXSfOXY6S6yDFy/jIEalYkWQS8A3gRsBJ4RZKVw+1KGohrgNXDbkLS/OUYqQ67BsfIeckQqNmyCthRVZ+vqq8D1wNrhtyTNOeq6hPAl4fdh6R5zTFSneQYOX8ZAjVblgA7+z5PtpokSV3nGClpXjEEarZkiprPH5EkyTFS0jxjCNRsmQSW9X1eCjw4pF4kSZpPHCMlzSuGQM2WvwJWJDkryeOBtcCWIfckSdJ84BgpaV4xBGpWVNV+4LXAx4DtwOaq2jbcrqS5l+R9wC3AM5NMJrl02D1Jml8cI9VVjpHzV6q8JF2SJEmSusIzgZIkSZLUIYZASZIkSeoQQ6AkSZIkdYghUJIkSZI6xBAoSZIkSR1iCJTmuSSPPsb65UnuOspjXpPkZcfXmSRJw+P4KB07Q6AkSZIkdYghUBoRSZ6cZGuSTyW5M8mavtUnJNmU5LNJ3p/kiW2f85L8eZLbk3wsyeIhtS9J0pxwfJSOniFQGh3/APx4VT0P+AHgN5OkrXsmsLGqvgv4KvAzSU4Efgd4WVWdB7wb2DCEviVJmkuOj9JROmHYDUiasQC/luQFwDeAJcCZbd3Oqvo/bfm9wM8BHwXOAW5qY+EiYNdAO5Ykae45PkpHyRAojY5/C4wB51XVPya5H3hCW1eHbFv0BsVtVfW9g2tRkqSBc3yUjpKXg0qj41uAPW2A+wHgGX3rnp7k4GD2CuCTwD3A2MF6khOTnD3QjiVJmnuOj9JRMgRKo+M6YDzJBL2/en6ub912YF2SzwKnAVdX1deBlwG/keQzwB3A9w22ZUmS5pzjo3SUUnXoWXJJkiRJ0kLlmUBJkiRJ6hBDoCRJkiR1iCFQkiRJkjrEEChJkiRJHWIIlCRJkqQOMQRKkiRJUocYAiVJkiSpQ/5/2weFjXf+rOAAAAAASUVORK5CYII=",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(2,2, figsize=(15,10))\n",
    "sns.countplot(df_senate['label'], ax=ax[0,0])\n",
    "sns.countplot(df_house['label'], ax=ax[0,1])\n",
    "sns.countplot(df_presidential['label'], ax=ax[1,0])\n",
    "sns.countplot(df['label'], ax=ax[1,1])\n",
    "ax[0,0].set_title('Senate')\n",
    "ax[0,1].set_title('House')\n",
    "ax[1,0].set_title('Presidential')\n",
    "ax[1,1].set_title('All')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "baselines: {'senate': 0.6443089430894309, 'house': 0.4894237782640408, 'presidential': 0.5352112676056338, 'all': 0.5068664169787765}\n"
=======
      "baselines: {'senate': 0.8466257668711656, 'house': 0.7385093167701864, 'presidential': 0.7713625866050808, 'all': 0.7523978315262719}\n"
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     ]
    }
   ],
   "source": [
    "#save all precentage of label 0 and label 1 in each segment\n",
    "senate_0 = df_senate[df_senate['label']==0].shape[0]/df_senate.shape[0]\n",
    "senate_1 = df_senate[df_senate['label']==1].shape[0]/df_senate.shape[0]\n",
    "house_0 = df_house[df_house['label']==0].shape[0]/df_house.shape[0]\n",
    "house_1 = df_house[df_house['label']==1].shape[0]/df_house.shape[0]\n",
    "presidential_0 = df_presidential[df_presidential['label']==0].shape[0]/df_presidential.shape[0]\n",
    "presidential_1 = df_presidential[df_presidential['label']==1].shape[0]/df_presidential.shape[0]\n",
    "all_0 = df[df['label']==0].shape[0]/df.shape[0]\n",
    "all_1 = df[df['label']==1].shape[0]/df.shape[0]\n",
    "\n",
    "#save all 0 classes to dictionary\n",
    "dict_0 = {'senate': senate_0, 'house': house_0, 'presidential': presidential_0, 'all': all_0}\n",
    "\n",
    "print(f'baselines: {dict_0}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our best models to a zero-rate classifier (baseline)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_accuracy = metrics.sort_values(by='test_accuracy', ascending=False).groupby('segment').head(1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_models_accuracy['baseline'] = best_models_accuracy['segment'].map(dict_0)\n",
    "\n",
    "#calculate test accuracy improvement over baseline\n",
    "best_models_accuracy['test_acc_impr'] = best_models_accuracy['test_accuracy'] - best_models_accuracy['baseline']\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr']/best_models_accuracy['baseline']\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr']*100\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr_pct'].apply(lambda x: round(x, 2))\n",
    "best_models_accuracy['test_acc_impr_pct'] = best_models_accuracy['test_acc_impr_pct'].apply(lambda x: str(x)+'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>model_name</th>\n",
       "      <th>segment</th>\n",
       "      <th>baseline</th>\n",
       "      <th>test_acc_impr</th>\n",
       "      <th>test_acc_impr_pct</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>Gradient-Boosting house seats</td>\n",
       "      <td>models-currcand/house-gbc.pkl</td>\n",
       "      <td>house</td>\n",
       "      <td>0.489424</td>\n",
       "      <td>0.452253</td>\n",
       "      <td>45.23%</td>\n",
       "      <td>0.941677</td>\n",
       "      <td>0.942584</td>\n",
       "      <td>0.933649</td>\n",
       "      <td>0.951691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stacking all seats</td>\n",
       "      <td>models-currcand/all-stacking.pkl</td>\n",
       "      <td>all</td>\n",
       "      <td>0.506866</td>\n",
       "      <td>0.421408</td>\n",
       "      <td>42.14%</td>\n",
       "      <td>0.928274</td>\n",
       "      <td>0.926518</td>\n",
       "      <td>0.910042</td>\n",
       "      <td>0.943601</td>\n",
       "      <td>0.986993</td>\n",
       "      <td>0.986959</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.991095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient-Boosting senate seats</td>\n",
       "      <td>models-currcand/senate-gbc.pkl</td>\n",
       "      <td>senate</td>\n",
       "      <td>0.644309</td>\n",
       "      <td>0.264782</td>\n",
       "      <td>26.48%</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.888889</td>\n",
=======
       "      <td>Stacking house seats</td>\n",
       "      <td>models/house-stacking.pkl</td>\n",
       "      <td>house</td>\n",
       "      <td>0.738509</td>\n",
       "      <td>0.224845</td>\n",
       "      <td>22.48%</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.925032</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.980745</td>\n",
       "      <td>0.963572</td>\n",
       "      <td>0.965842</td>\n",
       "      <td>0.961313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient-Boosting all seats</td>\n",
       "      <td>models/all-gbc.pkl</td>\n",
       "      <td>all</td>\n",
       "      <td>0.752398</td>\n",
       "      <td>0.200182</td>\n",
       "      <td>20.02%</td>\n",
       "      <td>0.952579</td>\n",
       "      <td>0.905895</td>\n",
       "      <td>0.884848</td>\n",
       "      <td>0.927966</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient-Boosting presidential seats</td>\n",
       "      <td>models/presidential-gbc.pkl</td>\n",
       "      <td>presidential</td>\n",
       "      <td>0.771363</td>\n",
       "      <td>0.171166</td>\n",
       "      <td>17.12%</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.900000</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
<<<<<<< HEAD
       "      <td>Stacking presidential seats</td>\n",
       "      <td>models-currcand/presidential-stacking.pkl</td>\n",
       "      <td>presidential</td>\n",
       "      <td>0.535211</td>\n",
       "      <td>0.371765</td>\n",
       "      <td>37.18%</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
=======
       "      <td>Stacking senate seats</td>\n",
       "      <td>models/senate-stacking.pkl</td>\n",
       "      <td>senate</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>0.092239</td>\n",
       "      <td>9.22%</td>\n",
       "      <td>0.938865</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.891304</td>\n",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                  experiment_name                                 model_name  \\\n",
       "0   Gradient-Boosting house seats              models-currcand/house-gbc.pkl   \n",
       "1              Stacking all seats           models-currcand/all-stacking.pkl   \n",
       "2  Gradient-Boosting senate seats             models-currcand/senate-gbc.pkl   \n",
       "3     Stacking presidential seats  models-currcand/presidential-stacking.pkl   \n",
       "\n",
       "        segment  baseline  test_acc_impr test_acc_impr_pct  test_accuracy  \\\n",
       "0         house  0.489424       0.452253            45.23%       0.941677   \n",
       "1           all  0.506866       0.421408            42.14%       0.928274   \n",
       "2        senate  0.644309       0.264782            26.48%       0.909091   \n",
       "3  presidential  0.535211       0.371765            37.18%       0.906977   \n",
       "\n",
       "    test_f1  test_precision  test_recall  train_accuracy  train_f1  \\\n",
       "0  0.942584        0.933649     0.951691        1.000000  1.000000   \n",
       "1  0.926518        0.910042     0.943601        0.986993  0.986959   \n",
       "2  0.876712        0.864865     0.888889        1.000000  1.000000   \n",
       "3  0.888889        0.888889     0.888889        1.000000  1.000000   \n",
       "\n",
       "   train_precision  train_recall  \n",
       "0         1.000000      1.000000  \n",
       "1         0.982857      0.991095  \n",
       "2         1.000000      1.000000  \n",
       "3         1.000000      1.000000  "
      ]
     },
     "execution_count": 53,
=======
       "                        experiment_name                   model_name  \\\n",
       "0                  Stacking house seats    models/house-stacking.pkl   \n",
       "1           Gradient-Boosting all seats           models/all-gbc.pkl   \n",
       "2  Gradient-Boosting presidential seats  models/presidential-gbc.pkl   \n",
       "3                 Stacking senate seats   models/senate-stacking.pkl   \n",
       "\n",
       "        segment  baseline  test_acc_impr test_acc_impr_pct  test_accuracy  \\\n",
       "0         house  0.738509       0.224845            22.48%       0.963354   \n",
       "1           all  0.752398       0.200182            20.02%       0.952579   \n",
       "2  presidential  0.771363       0.171166            17.12%       0.942529   \n",
       "3        senate  0.846626       0.092239             9.22%       0.938865   \n",
       "\n",
       "    test_f1  test_precision  test_recall  train_accuracy  train_f1  \\\n",
       "0  0.925032        0.938144     0.912281        0.980745  0.963572   \n",
       "1  0.905895        0.884848     0.927966        0.999870  0.999737   \n",
       "2  0.878049        0.857143     0.900000        1.000000  1.000000   \n",
       "3  0.805556        0.828571     0.783784        0.973684  0.911111   \n",
       "\n",
       "   train_precision  train_recall  \n",
       "0         0.965842      0.961313  \n",
       "1         1.000000      0.999475  \n",
       "2         1.000000      1.000000  \n",
       "3         0.931818      0.891304  "
      ]
     },
     "execution_count": 136,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_models_accuracy = best_models_accuracy[['experiment_name', 'model_name', 'segment', 'baseline', 'test_acc_impr', 'test_acc_impr_pct', 'test_accuracy', 'test_f1', 'test_precision', 'test_recall', 'train_accuracy', 'train_f1', 'train_precision', 'train_recall']]\n",
    "best_models_accuracy.reset_index(drop=True, inplace=True)\n",
    "best_models_accuracy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
=======
   "execution_count": null,
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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",
>>>>>>> fc57789d8a90e0a655231bc3208cf964aa166621
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot test accuracy improvement over baseline add test_accr_impr to baseline\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.barplot(x='segment', y='test_acc_impr', data=best_models_accuracy, ax=ax)\n",
    "ax.set_title('Test Accuracy Improvement over Baseline')\n",
    "\n",
    "for i, v in enumerate(best_models_accuracy['experiment_name']):\n",
    "    ax.text(i-.25, best_models_accuracy['test_acc_impr'][i]+.001, v, fontsize=10)\n",
    "\n",
    " \n",
    "for i, v in enumerate(best_models_accuracy['test_acc_impr_pct']):\n",
    "    ax.text(i-.50, best_models_accuracy['test_acc_impr'][i]+.0010, v, fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMHS_WH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "548c434b22017ed83120037e69c5bbe81702091f05abd27c68dbd10b5a598561"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
