{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jaaFmM__H38b",
        "uaTiD7tyK8_N"
      ],
      "authorship_tag": "ABX9TyMGhPId/v7hLx+4KSpxumlk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gimenopea/CSCI6364/blob/main/Classification_Evaluation_Metrics_PaulGimeno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Paul Gimeno Fall 2022**\n",
        "\n",
        "CSCI 6364 Machine Learning\n",
        "\n",
        "pgimeno@gwu.edu "
      ],
      "metadata": {
        "id": "EmaMKgbgqw3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Classification Metric Evaluation**\n",
        "\n",
        "\n",
        "\n",
        "A model using a classifier has been trained and two vectors (y_actual and y_predict) is saved for a particular run. This notebook details an analysis of model performance using various evaluation metrics.\n",
        "\n",
        "* **We have determined that there is baseline F score of 0.65 prior to this model's specific run** "
      ],
      "metadata": {
        "id": "ugUSnrEy8w4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "7mxIXhaY8RwS"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after model training, we evaluate our model with our predicted classes and compare it with actual classes. In this particular case, we assume that 1's reach the threshold where it considered in the positive class and 0 being in the negative class.\n",
        "y_actual = [0, 1, 1, 0, 0, 1]\n",
        "y_predict = [0, 1, 1, 1, 0, 1]"
      ],
      "metadata": {
        "id": "RJSD69AhgPTd"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a confusion matrix is constructed to aggrgate prediction performance against our true value (or in this case, our test sample)\n",
        "cm = confusion_matrix(y_actual, y_predict)\n",
        "#the ravel method convers a 2d numpy array to a single list that sequentially lists true negative, false positive, false negative and true positive in this order. As we can see, we can observe this order by manually observing y_actual and y_predict indexes.\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "print(cm.ravel())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emtpxt0cncHS",
        "outputId": "c962fa0c-9770-4615-9a79-9102173bdb45"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting the confusion matrix using sklearn's library\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JCIdZmG0niL6",
        "outputId": "b69bd69c-12c9-4579-c2c9-0a094627224a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f0e6ef3db10>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Confusion Matrix**"
      ],
      "metadata": {
        "id": "UimHsPWy-JZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'The True Positives (bottom right) in the matrix: {tp}, indicates predicted true values that are TRUE \\n\\\n",
        "The True Negatives (upper left) in the matrix: {tn}, indicates predicted false values that are FALSE \\n\\\n",
        "The False Positives in the matrix (upper right): {fp}, indicates predicted positive values that are FALSE \\n\\\n",
        "The False Negatives in the matrix (lower left): {fn}, indicates predicted negative values that are TRUE ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bImkPfzYn1dM",
        "outputId": "025c0ca0-1972-4689-9cea-d4e47001f2ce"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The True Positives (bottom right) in the matrix: 3, indicates predicted true values that are TRUE \n",
            "The True Negatives (upper left) in the matrix: 2, indicates predicted false values that are FALSE \n",
            "The False Positives in the matrix (upper right): 1, indicates predicted positive values that are FALSE \n",
            "The False Negatives in the matrix (lower left): 0, indicates predicted negative values that are TRUE \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Accuracy**"
      ],
      "metadata": {
        "id": "sYn2_Nm8CfJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy is defined as the total correct predictions over all samples, TP + TN / (TP + TN + FP + FN), in this evaluation, the model accuracy is: {round((tp + tn) / (tp+tn+fp+fn))*100}%\\n\\\n",
        "This can be interpreted as out of 100 samples, it correctly predicted 83 cases')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg8KQMhXoorh",
        "outputId": "7088165e-8ee9-465c-8b92-3703d28eb97d"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is defined as the total correct predictions over all samples, TP + TN / (TP + TN + FP + FN), in this evaluation, the model accuracy is: 100%\n",
            "This can be interpreted as out of 100 samples, it correctly predicted 83 cases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As an alternative, we can use sklearn's evaluation metric method called accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_actual, y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oPHBnLPoqr5",
        "outputId": "811929bf-14f8-425d-f127-4e2f821a71a7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision\n",
        "\n",
        "Often times determining accuracy is not adequate to evaluate model performance if the sample is biased. For example, if in 100 samples, there's only 1 instance of the positive class, the model can always predict the negative class and have a 99/100 accuracy. If we care about the positive class prediction, the accuracy metric is misleading.\n",
        "\n",
        "**Precision** can be defined as: of all the predicted positive classes, how many are actually positive? or in another term, how many correct positive predictions were made across all positive samples.\n",
        "\n",
        "This measure would be weighed more if we actually care about the predictive power of the model of a particular class in addition for accounting for cases where the sample distribution are heavily biased."
      ],
      "metadata": {
        "id": "jaaFmM__H38b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'precision can be manually calculated as tp / tp + fp, in the example statement the value is: {tp / (tp + fp)}, \\n\\\n",
        "there were {tp} positive predictions (tp) out of {tp + fp} (tp + fp) positive samples  ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmHm2rZtEA2s",
        "outputId": "afc4a84d-3dc9-4aa7-ed80-750de5eb1d08"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision can be manually calculated as tp / tp + fp, in the example statement the value is: 0.75, \n",
            "there were 3 positive predictions (tp) out of 4 (tp + fp) positive samples  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly we can compute this value using sklearn's precision_score method\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(precision_score(y_actual,y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSvdWLmKuq4q",
        "outputId": "76140944-61f8-48ca-aabd-161df3835cb6"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recall\n",
        "\n",
        "Closely related to related to precision is the measure called recall.\n",
        "\n",
        "**Recall** can be defined as: of all the actual positive classes, how many are predicted as positive?"
      ],
      "metadata": {
        "id": "uaTiD7tyK8_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'recall can be manually calculated as tp / tp + fn, in the example statement the value is: {tp / (tp + fn)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT3KzFknLAHr",
        "outputId": "2202ba28-0a16-41a7-fe3d-c43b124a7aa6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "recall can be manually calculated as tp / tp + fn, in the example statement the value is: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly we can compute this value using sklearn's recall method\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "print(recall_score(y_actual, y_predict))\n",
        "\n",
        "#with a recall score of 1, we were able to predict all of the positive classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiAZhX_88q2G",
        "outputId": "cd3de738-a127-46e1-c673-18810aace2d1"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F Score\n",
        "\n",
        "Depending on the problem statement, we either value precision over recall if for example, we want to reduce the instances or consequences of false positives. In this classification problem, if the positive class indicates a decision to retaliate using nuclear weapons (positive class) vs not retaliate using nuclear weapons (negative class), we would value high precision in a higher priority as this ensures that a large proportion of our predicted positive class are actually positive class. \n",
        "\n",
        "Recall would be weighed more if the instances of false negatives (type II) errors are not acceptable.\n",
        "\n",
        "We can use a ratio of precision and recall to determine the model's accuracy. [F1 score is the harmonic mean of precision and recall.](https://https://en.wikipedia.org/wiki/F-score) \n",
        "\n",
        "for this problem statement, we can calculate an F1 score using:\n",
        "\n",
        "<img src = \"https://wikimedia.org/api/rest_v1/media/math/render/svg/b006f28426fcf95c08de4be0597f7894d86bfccd\">"
      ],
      "metadata": {
        "id": "uUCtjEgUkoiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This model run's F1 score which is a balanced approach in weighing precision and recall\n",
        "\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "\n",
        "f_1 = (2*precision*recall)/(precision+recall)\n",
        "print(f_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6BOTO2RkqE1",
        "outputId": "f71e52e9-3e20-4d23-b0fe-d23f2fed3f3f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**F beta Scores**\n",
        "\n",
        "If we want to weigh either recall or precision over another, we can designate a beta parameter to the f score using the formula\n",
        "\n",
        "<img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/136f45612c08805f4254f63d2f2524bc25075fff'>\n",
        "\n",
        "[source](https://en.wikipedia.org/wiki/F-score)"
      ],
      "metadata": {
        "id": "uGCzqfrC9w7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#in the case of beta = 0.5, more weight on precision but less on precision \n",
        "\n",
        "beta_05 = 0.5\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f_score_beta05 = (1 + beta**2)*(precision*recall)*1/(((beta**2) * precision) + recall)\n",
        "print(f_score_beta05)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq-1sh1ctxSx",
        "outputId": "c47deb68-29d7-49b6-edc4-cceeb3104a31"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7894736842105263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#in the case of beta = 2, more weight on recall and less weight on precision\n",
        "beta_2 = 2\n",
        "precision = tp / (tp + fp)\n",
        "recall = tp / (tp + fn)\n",
        "f_2 = (1 + beta_2**2)*(precision*recall)*1/(((beta_2**2) * precision) + recall)\n",
        "print(f_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5ISP0r5pjKG",
        "outputId": "3904912b-dfbf-4928-bdc9-4ae74a0ff34d"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing model metrics to baseline\n",
        "\n",
        "our baseline F1 score is .65\n",
        "\n",
        "* Since this model's F1 score is .85, we determine that this model is more accurate than the baseline with a balanced precision/recall Fmeasure\n",
        "\n",
        "* If we value precision and determine that false positives are detrimental to decision making, we can compare the baseline's f1 score with a beta of .5 for example to this model's f1 score of .789\n",
        "\n",
        "* if we value predicting as much positive classes from the sample, having a higher recall or higher beta would be ideal compared to our baseline."
      ],
      "metadata": {
        "id": "8vPENu2O_tG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we also can calculate the f1 measure using the sklearn classification_report measure\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_actual,y_predict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhNb4MRHrIcJ",
        "outputId": "81e3cff7-b6ff-4fd7-bd0e-0af0ac84bda4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.75      1.00      0.86         3\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.83      0.83         6\n",
            "weighted avg       0.88      0.83      0.83         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7w5ZUUVrR-a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}